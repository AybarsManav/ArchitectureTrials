{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Cloning coatnet.py and importing modules","metadata":{"_uuid":"205e59d8-8f9e-4c3f-9101-27359af627ac","_cell_guid":"5358f0f0-d0c0-42d5-b5db-9e350ae1b311","id":"bhqaMz7iWFIQ","trusted":true}},{"cell_type":"code","source":"!pip install einops","metadata":{"_uuid":"f01f7ead-6385-43f8-bb9d-711343efdb37","_cell_guid":"db14bb74-b388-4108-819d-4fcaf6492b76","collapsed":false,"id":"pKFI-wMRYTyO","outputId":"26f0c889-0273-44f0-d5d9-2daa21ebffac","execution":{"iopub.status.busy":"2022-08-05T14:02:18.818321Z","iopub.execute_input":"2022-08-05T14:02:18.819539Z","iopub.status.idle":"2022-08-05T14:02:28.022534Z","shell.execute_reply.started":"2022-08-05T14:02:18.819482Z","shell.execute_reply":"2022-08-05T14:02:28.021284Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n\nfrom einops import rearrange\nfrom einops.layers.torch import Rearrange\n\n\ndef conv_3x3_bn(inp, oup, image_size, downsample=False):\n    stride = 1 if downsample == False else 2\n    return nn.Sequential(\n        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n        nn.BatchNorm2d(oup),\n        nn.GELU()\n    )\n\n\nclass PreNorm(nn.Module):\n    def __init__(self, dim, fn, norm):\n        super().__init__()\n        self.norm = norm(dim)\n        self.fn = fn\n\n    def forward(self, x, **kwargs):\n        return self.fn(self.norm(x), **kwargs)\n\n\nclass SE(nn.Module):\n    def __init__(self, inp, oup, expansion=0.25):\n        super().__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Sequential(\n            nn.Linear(oup, int(inp * expansion), bias=False),\n            nn.GELU(),\n            nn.Linear(int(inp * expansion), oup, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        b, c, _, _ = x.size()\n        y = self.avg_pool(x).view(b, c)\n        y = self.fc(y).view(b, c, 1, 1)\n        return x * y\n\n\nclass FeedForward(nn.Module):\n    def __init__(self, dim, hidden_dim, dropout=0.):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(dim, hidden_dim),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, dim),\n            nn.Dropout(dropout)\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\n\nclass MBConv(nn.Module):\n    def __init__(self, inp, oup, image_size, downsample=False, expansion=4):\n        super().__init__()\n        self.downsample = downsample\n        stride = 1 if self.downsample == False else 2\n        hidden_dim = int(inp * expansion)\n\n        if self.downsample:\n            self.pool = nn.MaxPool2d(3, 2, 1)\n            self.proj = nn.Conv2d(inp, oup, 1, 1, 0, bias=False)\n\n        if expansion == 1:\n            self.conv = nn.Sequential(\n                # dw\n                nn.Conv2d(hidden_dim, hidden_dim, 3, stride,\n                          1, groups=hidden_dim, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                nn.GELU(),\n                # pw-linear\n                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(oup),\n            )\n        else:\n            self.conv = nn.Sequential(\n                # pw\n                # down-sample in the first conv\n                nn.Conv2d(inp, hidden_dim, 1, stride, 0, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                nn.GELU(),\n                # dw\n                nn.Conv2d(hidden_dim, hidden_dim, 3, 1, 1,\n                          groups=hidden_dim, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                nn.GELU(),\n                SE(inp, hidden_dim),\n                # pw-linear\n                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(oup),\n            )\n        \n        self.conv = PreNorm(inp, self.conv, nn.BatchNorm2d)\n\n    def forward(self, x):\n        if self.downsample:\n            return self.proj(self.pool(x)) + self.conv(x)\n        else:\n            return x + self.conv(x)\n\n\nclass Attention(nn.Module):\n    def __init__(self, inp, oup, image_size, heads=8, dim_head=32, dropout=0.):\n        super().__init__()\n        inner_dim = dim_head * heads\n        project_out = not (heads == 1 and dim_head == inp)\n\n        self.ih, self.iw = image_size\n\n        self.heads = heads\n        self.scale = dim_head ** -0.5\n\n        # parameter table of relative position bias\n        self.relative_bias_table = nn.Parameter(\n            torch.zeros((2 * self.ih - 1) * (2 * self.iw - 1), heads))\n\n        coords = torch.meshgrid((torch.arange(self.ih), torch.arange(self.iw)))\n        coords = torch.flatten(torch.stack(coords), 1)\n        relative_coords = coords[:, :, None] - coords[:, None, :]\n\n        relative_coords[0] += self.ih - 1\n        relative_coords[1] += self.iw - 1\n        relative_coords[0] *= 2 * self.iw - 1\n        relative_coords = rearrange(relative_coords, 'c h w -> h w c')\n        relative_index = relative_coords.sum(-1).flatten().unsqueeze(1)\n        self.register_buffer(\"relative_index\", relative_index)\n\n        self.attend = nn.Softmax(dim=-1)\n        self.to_qkv = nn.Linear(inp, inner_dim * 3, bias=False)\n\n        self.to_out = nn.Sequential(\n            nn.Linear(inner_dim, oup),\n            nn.Dropout(dropout)\n        ) if project_out else nn.Identity()\n\n    def forward(self, x):\n        qkv = self.to_qkv(x).chunk(3, dim=-1)\n        q, k, v = map(lambda t: rearrange(\n            t, 'b n (h d) -> b h n d', h=self.heads), qkv)\n\n        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n\n        # Use \"gather\" for more efficiency on GPUs\n        relative_bias = self.relative_bias_table.gather(\n            0, self.relative_index.repeat(1, self.heads))\n        relative_bias = rearrange(\n            relative_bias, '(h w) c -> 1 c h w', h=self.ih*self.iw, w=self.ih*self.iw)\n        dots = dots + relative_bias\n\n        attn = self.attend(dots)\n        out = torch.matmul(attn, v)\n        out = rearrange(out, 'b h n d -> b n (h d)')\n        out = self.to_out(out)\n        return out\n\n\nclass Transformer(nn.Module):\n    def __init__(self, inp, oup, image_size, heads=8, dim_head=32, downsample=False, dropout=0.):\n        super().__init__()\n        hidden_dim = int(inp * 4)\n\n        self.ih, self.iw = image_size\n        self.downsample = downsample\n\n        if self.downsample:\n            self.pool1 = nn.MaxPool2d(3, 2, 1)\n            self.pool2 = nn.MaxPool2d(3, 2, 1)\n            self.proj = nn.Conv2d(inp, oup, 1, 1, 0, bias=False)\n\n        self.attn = Attention(inp, oup, image_size, heads, dim_head, dropout)\n        self.ff = FeedForward(oup, hidden_dim, dropout)\n\n        self.attn = nn.Sequential(\n            Rearrange('b c ih iw -> b (ih iw) c'),\n            PreNorm(inp, self.attn, nn.LayerNorm),\n            Rearrange('b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n        )\n\n        self.ff = nn.Sequential(\n            Rearrange('b c ih iw -> b (ih iw) c'),\n            PreNorm(oup, self.ff, nn.LayerNorm),\n            Rearrange('b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n        )\n\n    def forward(self, x):\n        if self.downsample:\n            x = self.proj(self.pool1(x)) + self.attn(self.pool2(x))\n        else:\n            x = x + self.attn(x)\n        x = x + self.ff(x)\n        return x\n\n\nclass CoAtNet(nn.Module):\n    def __init__(self, image_size, in_channels, num_blocks, channels, num_classes=1000, block_types=['C', 'C', 'T', 'T']):\n        super().__init__()\n        ih, iw = image_size\n        block = {'C': MBConv, 'T': Transformer}\n\n        self.s0 = self._make_layer(\n            conv_3x3_bn, in_channels, channels[0], num_blocks[0], (ih // 2, iw // 2))\n        self.s1 = self._make_layer(\n            block[block_types[0]], channels[0], channels[1], num_blocks[1], (ih // 4, iw // 4))\n        self.s2 = self._make_layer(\n            block[block_types[1]], channels[1], channels[2], num_blocks[2], (ih // 8, iw // 8))\n        self.s3 = self._make_layer(\n            block[block_types[2]], channels[2], channels[3], num_blocks[3], (ih // 16, iw // 16))\n        self.s4 = self._make_layer(\n            block[block_types[3]], channels[3], channels[4], num_blocks[4], (ih // 32, iw // 32))\n\n        self.pool = nn.AvgPool2d(ih // 32, 1)\n        self.fc = nn.Linear(channels[-1], num_classes, bias=False)\n\n    def forward(self, x):\n        x = self.s0(x)\n        x = self.s1(x)\n        x = self.s2(x)\n        x = self.s3(x)\n        x = self.s4(x)\n\n        x = self.pool(x).view(-1, x.shape[1])\n        x = self.fc(x)\n        return x\n\n    def _make_layer(self, block, inp, oup, depth, image_size):\n        layers = nn.ModuleList([])\n        for i in range(depth):\n            if i == 0:\n                layers.append(block(inp, oup, image_size, downsample=True))\n            else:\n                layers.append(block(oup, oup, image_size))\n        return nn.Sequential(*layers)\n\n\ndef coatnet_0():\n    num_blocks = [2, 2, 3, 5, 2]            # L\n    channels = [64, 96, 192, 384, 768]      # D\n    return CoAtNet((224, 224), 3, num_blocks, channels, num_classes=1000)\n\n\ndef coatnet_1():\n    num_blocks = [2, 2, 6, 14, 2]           # L\n    channels = [64, 96, 192, 384, 768]      # D\n    return CoAtNet((224, 224), 3, num_blocks, channels, num_classes=1000)\n\n\ndef coatnet_2():\n    num_blocks = [2, 2, 6, 14, 2]           # L\n    channels = [128, 128, 256, 512, 1026]   # D\n    return CoAtNet((224, 224), 3, num_blocks, channels, num_classes=1000)\n\n\ndef coatnet_3():\n    num_blocks = [2, 2, 6, 14, 2]           # L\n    channels = [192, 192, 384, 768, 1536]   # D\n    return CoAtNet((224, 224), 3, num_blocks, channels, num_classes=1000)\n\n\ndef coatnet_4():\n    num_blocks = [2, 2, 12, 28, 2]          # L\n    channels = [192, 192, 384, 768, 1536]   # D\n    return CoAtNet((224, 224), 3, num_blocks, channels, num_classes=1000)\n\n\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)","metadata":{"_uuid":"841f0d8d-639d-4359-a7f4-d2443d574fff","_cell_guid":"a5ff7027-fbea-43e9-832f-997eb8be9cf1","collapsed":false,"id":"P2aTHM5KWb0y","execution":{"iopub.status.busy":"2022-08-05T14:02:29.878759Z","iopub.execute_input":"2022-08-05T14:02:29.879632Z","iopub.status.idle":"2022-08-05T14:02:29.923962Z","shell.execute_reply.started":"2022-08-05T14:02:29.879587Z","shell.execute_reply":"2022-08-05T14:02:29.922932Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Random 3x224x224 images","metadata":{"_uuid":"a4dba178-88ed-4854-bb78-3ef6047687c9","_cell_guid":"09b7ada8-50c6-432d-b4f1-6f0f7160a1bb","id":"scZF68EQW1C2","trusted":true}},{"cell_type":"code","source":"images = torch.randn(5,3,32,32)","metadata":{"_uuid":"db2f3c48-461d-4731-9cad-907f93c9c69d","_cell_guid":"b6f347dc-25ce-4083-8db9-135e3d99cc6e","collapsed":false,"id":"Z1pLuKE6WeRz","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s0 = conv_3x3_bn(3,64,(16,16),downsample = True) #imsize is the output size\ns0_output = s0(images)\nprint(s0_output.shape)","metadata":{"_uuid":"566f6cef-973b-41d3-af09-fb60b4b1e7a7","_cell_guid":"cb20a4fb-b11d-410e-96ea-a72dd386eb69","collapsed":false,"id":"K3SvzRBAXFWp","outputId":"ca87afcc-0546-4871-d258-98c57c7df489","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s1 = MBConv(64,96,(8,8),downsample = True,expansion=4)\ns1_output = s1(s0_output)\nprint(s1_output.shape)","metadata":{"_uuid":"cd45143f-ea97-4af0-9dab-9bb1708b1548","_cell_guid":"27569e52-c9a5-4664-b2a1-5d2301e17c33","collapsed":false,"id":"8TMWb8U_YZz2","outputId":"d0b07c52-8cc3-45de-9ed1-d6caf2fbcc4f","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s2 = MBConv(96,192,(4,4),downsample = True, expansion = 4)\ns2_output = s2(s1_output)\nprint(s2_output.shape)","metadata":{"_uuid":"f28e6c16-9da1-49da-b859-a8f753ca3209","_cell_guid":"a9a31fd6-cd4d-4fec-b925-eb2705193758","collapsed":false,"id":"3Shs7IseZwIZ","outputId":"bd129de4-6415-4d4f-9799-07cf7500041b","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s3 = Transformer(192,384,(2,2),downsample = True)\ns3_output = s3(s2_output)\nprint(s3_output.shape)","metadata":{"_uuid":"1dc9743e-a5e7-47eb-8dde-9f9bf8fc0126","_cell_guid":"8b7185df-6e73-40e9-9576-438f67a4e5c0","collapsed":false,"id":"l1oVa06xZ4e1","outputId":"ea4163df-54a3-423e-949b-cbf27988a6b7","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s4 = Transformer(384,768,(1,1),downsample = True)\ns4_output = s4(s3_output)\nprint(s4_output.shape)","metadata":{"_uuid":"4fa487f3-d189-4c85-ae39-d3a869754757","_cell_guid":"035d6ec4-7570-4c44-bd1c-4b0e00b2e180","collapsed":false,"id":"t3_eN1yLjBi0","outputId":"98384891-84e7-4589-cb49-a8824d563c6f","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"upsamplerrr = nn.ConvTranspose2d(3072,200,2,2)\ntest = upsamplerrr(s4_output)\nprint(test.shape)","metadata":{"_uuid":"5cea8bcf-fa5a-41f8-9ffb-046704640215","_cell_guid":"5725ffa4-855e-4995-959a-cc254f90fc6c","collapsed":false,"id":"3bTBJ4XtHN-v","outputId":"d15daf53-01e2-4310-dc64-06730fb54839","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s4_output[0,0,:,:]","metadata":{"_uuid":"7d9c6719-592f-4415-80ac-4cdc1007edaf","_cell_guid":"d64f6260-6c21-451b-90e9-9aaf3b1571aa","collapsed":false,"id":"yiySnFMXjHp6","outputId":"624a1af2-809c-44f5-ad89-068bc9df8e8d","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Symmetrical Coatnet","metadata":{"_uuid":"92e580c9-d758-49e4-b265-437ae65de655","_cell_guid":"edae7c08-a78d-4b2a-9892-1cd9b3e3688c","id":"aMlS6LAJmNCt","trusted":true}},{"cell_type":"code","source":"#----------------Same as CoAtNet--------------------------\nimport torch\nimport torch.nn as nn\n\n\nfrom einops import rearrange\nfrom einops.layers.torch import Rearrange\n\nclass PreNorm(nn.Module):\n    def __init__(self, dim, fn, norm):\n        super().__init__()\n        self.norm = norm(dim)\n        self.fn = fn\n\n    def forward(self, x, **kwargs):\n        return self.fn(self.norm(x), **kwargs)\n\n\nclass SE(nn.Module):\n    def __init__(self, inp, oup, expansion=0.25):\n        super().__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Sequential(\n            nn.Linear(oup, int(inp * expansion), bias=False),\n            nn.GELU(),\n            nn.Linear(int(inp * expansion), oup, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        b, c, _, _ = x.size()\n        y = self.avg_pool(x).view(b, c)\n        y = self.fc(y).view(b, c, 1, 1)\n        return x * y\nclass Attention(nn.Module):\n    def __init__(self, inp, oup, image_size, heads=8, dim_head=32, dropout=0.):\n        super().__init__()\n        inner_dim = dim_head * heads\n        project_out = not (heads == 1 and dim_head == inp)\n\n        self.ih, self.iw = image_size\n\n        self.heads = heads\n        self.scale = dim_head ** -0.5\n\n        # parameter table of relative position bias\n        self.relative_bias_table = nn.Parameter(\n            torch.zeros((2 * self.ih - 1) * (2 * self.iw - 1), heads))\n\n        coords = torch.meshgrid((torch.arange(self.ih), torch.arange(self.iw)))\n        coords = torch.flatten(torch.stack(coords), 1)\n        relative_coords = coords[:, :, None] - coords[:, None, :]\n\n        relative_coords[0] += self.ih - 1\n        relative_coords[1] += self.iw - 1\n        relative_coords[0] *= 2 * self.iw - 1\n        relative_coords = rearrange(relative_coords, 'c h w -> h w c')\n        relative_index = relative_coords.sum(-1).flatten().unsqueeze(1)\n        self.register_buffer(\"relative_index\", relative_index)\n\n        self.attend = nn.Softmax(dim=-1)\n        self.to_qkv = nn.Linear(inp, inner_dim * 3, bias=False)\n\n        self.to_out = nn.Sequential(\n            nn.Linear(inner_dim, oup),\n            nn.Dropout(dropout)\n        ) if project_out else nn.Identity()\n\n    def forward(self, x):\n        qkv = self.to_qkv(x).chunk(3, dim=-1)\n        q, k, v = map(lambda t: rearrange(\n            t, 'b n (h d) -> b h n d', h=self.heads), qkv)\n\n        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n\n        # Use \"gather\" for more efficiency on GPUs\n        relative_bias = self.relative_bias_table.gather(\n            0, self.relative_index.repeat(1, self.heads))\n        relative_bias = rearrange(\n            relative_bias, '(h w) c -> 1 c h w', h=self.ih*self.iw, w=self.ih*self.iw)\n        dots = dots + relative_bias\n\n        attn = self.attend(dots)\n        out = torch.matmul(attn, v)\n        out = rearrange(out, 'b h n d -> b n (h d)')\n        out = self.to_out(out)\n        return out\n\n# -----------------Symmetric CoAtNet Modules--------------\nclass Bicubic_upsampler(nn.Module):\n    def __init__(self,scale_factor,mode):\n      super(Bicubic_upsampler,self).__init__()\n      self.upsampler = nn.functional.interpolate\n      self.scale_factor = scale_factor\n      self.mode = mode\n    def forward(self,x):\n      x = self.upsampler(x,scale_factor = self.scale_factor, mode = self.mode)\n      return x\n\n\nclass InverseTransformer(nn.Module):\n    def __init__(self, inp, oup, image_size, heads=8, dim_head=32, upsample=False, dropout=0.):\n        super().__init__()\n        \n\n        self.ih, self.iw = image_size\n        self.upsample = upsample\n        \n        \n        if self.upsample: #We can change the upsampling method at some point.\n          #Maybe using bicubic interpolation might be better\n          \n          # self.upsampler = nn.PixelShuffle(2) # 2 is the upsample factor can be a hyperparameter\n          # inp = int(inp/4) # after upsampling \n          self.upsampler = nn.ConvTranspose2d(inp,inp,kernel_size=2,stride=2,bias=False) \n\n          # Not needed since pixelshuffle reduces channels while upsampling, Needed when using bicubic interpolation\n          # self.upsampler = Bicubic_upsampler(scale_factor = 2, mode = \"bicubic\")\n          self.proj = nn.ConvTranspose2d(inp, oup, 1, 1, 0, bias=False) \n\n        hidden_dim = int(inp * 4)\n        self.attn = Attention(inp, oup, image_size, heads, dim_head, dropout)\n        self.ff = FeedForward(oup, hidden_dim, dropout)\n\n        self.attn = nn.Sequential(\n            Rearrange('b c ih iw -> b (ih iw) c'),\n            PreNorm(inp, self.attn, nn.LayerNorm),\n            Rearrange('b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n        )\n\n        self.ff = nn.Sequential(\n            Rearrange('b c ih iw -> b (ih iw) c'),\n            PreNorm(oup, self.ff, nn.LayerNorm),\n            Rearrange('b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n        )\n\n    def forward(self, x):\n        if self.upsample:\n            x = self.proj(self.upsampler(x)) + self.attn(self.upsampler(x))\n        else:\n            x = x + self.attn(x)\n        x = x + self.ff(x)\n        return x\n\nclass InverseMBConv(nn.Module):\n    def __init__(self, inp, oup, image_size, upsample=False, expansion=4):\n        super().__init__()\n        self.upsample = upsample\n        stride = 1 if self.upsample == False else 2\n        output_padding = 0 if self.upsample == False else 1\n\n        if self.upsample:\n            # self.upsampler = nn.PixelShuffle(2)\n            # self.upsampler = Bicubic_upsampler(scale_factor = 2, mode = \"bicubic\")\n            self.proj = nn.Conv2d(inp, oup, 1, 1, 0, bias=False)\n            self.upsampler = nn.ConvTranspose2d(inp,inp,kernel_size=2,stride=2,bias=False)\n        \n        hidden_dim = int(inp * expansion)\n      \n        if expansion == 1:\n            self.conv = nn.Sequential(\n                # dw\n                nn.Conv2d(inp, hidden_dim, 3, stride,\n                          1, groups=inp, bias=False,output_padding = output_padding),\n                nn.BatchNorm2d(hidden_dim),\n                nn.GELU(),\n                # pw-linear\n                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(oup),\n            )\n        else:\n            self.conv = nn.Sequential(\n                # pw\n                # up-sample in the first conv\n                nn.ConvTranspose2d(inp, hidden_dim, 1, stride, 0, bias=False,output_padding = output_padding),\n                nn.BatchNorm2d(hidden_dim),\n                nn.GELU(),\n                # dw\n                nn.Conv2d(hidden_dim, hidden_dim, 3, 1, 1,\n                          groups=hidden_dim, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                nn.GELU(),\n                SE(inp, hidden_dim),\n                # pw-linear\n                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(oup),\n            )\n        \n        self.conv = PreNorm(inp, self.conv, nn.BatchNorm2d)\n\n    def forward(self, x):\n        if self.upsample:\n            return self.proj(self.upsampler(x)) + self.conv(x)\n        else:\n            return x + self.conv(x)\n\ndef Inverse_conv_3x3_bn(inp, oup, image_size, upsample=False):\n    stride = 1 if upsample == False else 2\n    output_padding = 0 if upsample == False else 1\n    return nn.Sequential(\n        nn.ConvTranspose2d(inp, oup, 3, stride, 1, bias=False,output_padding = output_padding),\n        nn.BatchNorm2d(oup),\n        nn.Tanh()\n    )","metadata":{"_uuid":"a89dd56e-a12b-4ced-b9f6-22ebd8a7aa9f","_cell_guid":"70b324bc-0932-46d5-8a19-4f67444e652f","collapsed":false,"id":"2ngNf3yTm3l5","execution":{"iopub.status.busy":"2022-08-05T14:02:36.843879Z","iopub.execute_input":"2022-08-05T14:02:36.844249Z","iopub.status.idle":"2022-08-05T14:02:36.878902Z","shell.execute_reply.started":"2022-08-05T14:02:36.844216Z","shell.execute_reply":"2022-08-05T14:02:36.877734Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Recreating the Image","metadata":{"_uuid":"2c1d1a22-ecb7-49f3-99f4-3a95b4a8ccc8","_cell_guid":"d8e15a30-a4ea-4735-aed9-738558cf19c9","id":"2eldj5XvMWmw","trusted":true}},{"cell_type":"code","source":"g4 = InverseTransformer(768,384,(2,2),upsample = True)\ng4_output = g4(s4_output)\nprint(g4_output.shape)","metadata":{"_uuid":"1fff8180-91d2-4740-af38-8885d98a5848","_cell_guid":"48b5be19-17c7-4bff-96c6-cd024bf1b7de","collapsed":false,"id":"JWFvcuhz-A8q","outputId":"dcba1a08-50c9-4c61-bd0c-ba4261c446fb","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g3 = InverseTransformer(384,192,(4,4),upsample = True)\ng3_output = g3(g4_output)\nprint(g3_output.shape)","metadata":{"_uuid":"54ffb7ed-8948-4c94-ba7d-8e1394deb94c","_cell_guid":"e8d03a74-5e6a-4137-ba97-63d2de049aea","collapsed":false,"id":"ULmmBESw_C9U","outputId":"a37d28db-91f4-40c2-c89e-fc3fdce98307","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g2 = InverseMBConv(192,96,(8,8),upsample = True)\ng2_output = g2(g3_output)\nprint(g2_output.shape)","metadata":{"_uuid":"db297c08-b4aa-4620-9e59-ce1273ee0838","_cell_guid":"9a7405b8-5ac9-4b12-b128-45b43ba02f48","collapsed":false,"id":"RipHJjQtBG2V","outputId":"63c58a86-2428-4351-e395-66a8983d0736","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g1 = InverseMBConv(96,64,(16,16),upsample = True)\ng1_output = g1(g2_output)\nprint(g1_output.shape)","metadata":{"_uuid":"a00bb6d5-0ec4-44a8-b09f-b45a696715b8","_cell_guid":"8e1d84f2-377a-4b55-ab89-7bd6f17702ed","collapsed":false,"id":"O7sC2cEEBZbb","outputId":"603a9b86-0f46-4d89-fdbf-3c60721fec3e","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g0 = Inverse_conv_3x3_bn(64,3,(32,32),upsample = True)\ng0_output = g0(g1_output)\nprint(g0_output.shape)","metadata":{"_uuid":"5f6a99d9-d282-4abb-9618-d56573d85b7c","_cell_guid":"4285cd8b-523c-4070-b958-5629be67fc5b","collapsed":false,"id":"8SPUadwWBkPq","outputId":"92737496-2c01-4799-dfee-22b86ffb9aac","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lolconv = nn.ConvTranspose2d(192,768,1,2,0,bias=False, output_padding = 1)\ntest = lolconv(g3_output)\nprint(test.shape)\ntestconv = nn.ConvTranspose2d(768,768,3,1,1,groups = 768,bias = False)\ntest = testconv(test)\nprint(test.shape)\nse = SE(192,768)\ntest = se(test)\nprint(test.shape)\npwconv = nn.ConvTranspose2d(768,48,1,1,0,bias = False)\ntest = pwconv(test)\nprint(test.shape)","metadata":{"_uuid":"e90a079f-c50a-4072-859b-b3d83cbdae81","_cell_guid":"925955fc-c913-4492-a59b-a4ca252f0dbd","collapsed":false,"id":"o1LHCxOK-Qa9","outputId":"cb0da218-2928-4471-edc0-d694c858cdaf","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Merged Auto Encoder","metadata":{"_uuid":"1934adcd-23e8-480e-abe0-f120a157e853","_cell_guid":"615fa7a0-db7d-4089-8671-7ccf50a149a4","id":"80XoOA0xMVbk","trusted":true}},{"cell_type":"code","source":"# class MLP(nn.Module):\n#   def __init__(self,inp,oup,dropout = 0.):\n#     super().__init__()\n#     hidden = int(inp/2)\n#     self.fc1 = nn.Linear(inp,hidden)\n#     self.act = nn.GELU()\n#     self.fc2 = nn.Linear(hidden,oup)\n#     self.drop = nn.Dropout(dropout)\n#     self.norm_layer1 = nn.LayerNorm(hidden)\n#     self.norm_layer2 = nn.LayerNorm(oup)\n#   def forward(self,x):\n#     x = rearrange(x,'b c h w -> b h w c')\n#     x = self.fc1(x)\n#     # x = self.norm_layer1(x)\n#     x = self.act(x)\n#     x = self.drop(x)\n#     x = self.fc2(x)\n#     # x = self.norm_layer2(x)\n#     x = self.drop(x)\n#     x = rearrange(x,'b h w c -> b c h w')\n#     return x\n\n# class Inverse_MLP(nn.Module):\n#   def __init__(self,inp,oup,dropout = 0.):\n#     super().__init__()\n#     hidden = int(inp*2)\n#     self.fc1 = nn.Linear(inp,hidden)\n#     self.act = nn.GELU()\n#     self.fc2 = nn.Linear(hidden,oup)\n#     self.drop = nn.Dropout(dropout)\n#     self.norm_layer1 = nn.LayerNorm(hidden)\n#     self.norm_layer2 = nn.LayerNorm(oup)\n#   def forward(self,x):\n#     x = rearrange(x,'b c h w -> b h w c')\n#     x = self.fc1(x)\n#     # x = self.norm_layer1(x)\n#     x = self.act(x)\n#     x = self.drop(x)\n#     x = self.fc2(x)\n#     # x = self.norm_layer2(x)\n#     x = self.drop(x)\n#     x = rearrange(x,'b h w c -> b c h w')\n#     return x\n\nclass MergedAutoEncoder(nn.Module):\n  def __init__(self):\n    super(MergedAutoEncoder,self).__init__()\n    ######### encoder layers #########\n    #self.a0 =  conv_3x3_bn(3,12,(16,16),downsample = True)\n    self.a0 = self._make_layer_analysis(conv_3x3_bn,3,64,1,(16,16))\n    # self.gdn12 = GDN(12)\n\n    #self.a1 = MBConv(12,48,(8,8),downsample = True)\n    self.a1 = self._make_layer_analysis(MBConv,64,96,1,(8,8))\n    # self.gdn48 = GDN(48)\n\n    #self.a2 = MBConv(48,192,(4,4),downsample = True)\n    self.a2 = self._make_layer_analysis(MBConv,96,192,1,(4,4))\n    # self.gdn192 = GDN(192)\n\n    #self.a3 = Transformer(192,768,(2,2),downsample=True)\n    self.a3 = self._make_layer_analysis(Transformer,192,384,14,(2,2))\n    # self.gdn768 = GDN(768)\n\n    #self.a4 = Transformer(768,3072,(1,1),downsample = True)\n    self.a4 = self._make_layer_analysis(Transformer,384,768,2,(1,1))\n    # self.gdn3072 = GDN(3072)\n\n    # self.compress = MLP(3072,192)\n\n    ######### decoder layers #########\n\n    # self. decompress = Inverse_MLP(192,3072)\n\n    #self.s4 = InverseTransformer(3072,768,(2,2),upsample = True)\n    self.s4 = self._make_layer_synthesis(InverseTransformer,768,384,2,(2,2))\n    # self.igdn768 = GDN(768,inverse=True)\n\n    #self.s3 = InverseTransformer(768,192,(4,4),upsample = True)\n    self.s3 = self._make_layer_synthesis(InverseTransformer,384,192,14,(4,4))\n    # self.igdn192 = GDN(192,inverse=True)\n\n    # self.s2 = InverseMBConv(192,48,(8,8),upsample= True)\n    self.s2 = self._make_layer_synthesis(InverseMBConv,192,96,1,(8,8))\n\n    # self.igdn48= GDN(48,inverse=True)\n\n    # self.s1 = InverseMBConv(48,12,(16,16),upsample = True)\n    self.s1 = self._make_layer_synthesis(InverseMBConv,96,64,1,(16,16))\n    # self.igdn12= GDN(12,inverse=True)\n\n    # self.s0 = Inverse_conv_3x3_bn(12,3,(32,32),upsample = True)\n    self.s0 = self._make_layer_synthesis(Inverse_conv_3x3_bn,64,3,1,(32,32))\n    # self.igdn3= GDN(3,inverse=True)\n\n  def encode(self,x):\n    x = self.a0(x)\n    x = self.a1(x)\n    x = self.a2(x)\n    x = self.a3(x)\n    x = self.a4(x)\n    # x = self.compress(x)\n    return x\n\n  def decode(self,x):\n    # x = self.decompress(x)\n    x = self.s4(x)\n    x = self.s3(x)\n    x = self.s2(x)\n    x = self.s1(x)\n    x = self.s0(x)\n    return x\n\n  def forward(self,x):\n    enc = self.encode(x)\n    x_hat = self.decode(enc)\n    return x_hat\n\n  def _make_layer_analysis(self,block,inp,oup,depth,image_size):\n    layers = nn.ModuleList([])\n    for i in range(depth):\n      if i == 0:\n        layers.append(block(inp,oup,image_size,downsample = True))\n      else:\n        layers.append(block(oup,oup,image_size))\n    return nn.Sequential(*layers)\n  \n  def _make_layer_synthesis(self,block,inp,oup,depth,image_size):\n    layers = nn.ModuleList([])\n    for i in range(depth):\n      if i == 0:\n        layers.append(block(inp,oup,image_size,upsample = True))\n      else:\n        layers.append(block(oup,oup,image_size))\n    return nn.Sequential(*layers)","metadata":{"_uuid":"953bac38-68f2-494b-a6a5-754310008f03","_cell_guid":"1fad78ae-0811-44b9-a657-a6ae59d3a37a","collapsed":false,"id":"A2Y-1kwcMyku","execution":{"iopub.status.busy":"2022-08-05T14:04:45.212998Z","iopub.execute_input":"2022-08-05T14:04:45.213404Z","iopub.status.idle":"2022-08-05T14:04:45.230735Z","shell.execute_reply.started":"2022-08-05T14:04:45.213365Z","shell.execute_reply":"2022-08-05T14:04:45.229332Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Main","metadata":{"_uuid":"891697cf-2e9c-49df-8702-721dd294b468","_cell_guid":"11773716-8046-4306-843a-85d785aef409","id":"cbeQV_IoRS_i","trusted":true}},{"cell_type":"code","source":"from torch.nn.modules import loss\nfrom torchvision.transforms.transforms import RandomVerticalFlip\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.optim.lr_scheduler\nfrom tqdm import tqdm\nimport math\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntrain_transform = transforms.Compose(\n    [\n      # transforms.RandomHorizontalFlip(p=0.5),\n    #  transforms.RandomCrop(32,padding=4),\n    #  transforms.RandomVerticalFlip(p=0.5),\n     transforms.ToTensor(),\n     transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n    ])# normalize the image between [-1 1]\n\ntest_transform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n    ])\n\nbatch_size = 128\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=train_transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n                                          shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False,\n                                       download=True, transform=test_transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n                                         shuffle=False, num_workers=2)\n\n\nmodel = MergedAutoEncoder().to(device)\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(),lr = 2e-3)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',patience=2,verbose=True,factor=0.75)\n\ndef compute_psnr(img1, img2):\n    img1 = img1.astype(np.float64) \n    img2 = img2.astype(np.float64) \n    mse = np.mean((img1 - img2) ** 2)\n    if mse == 0:\n        return \"Same Image\"\n    return 10 * math.log10(1. / mse)\n\n######## Training #########\ndef train(dataloader,model,loss_fn,optimizer):\n  size = len(dataloader.dataset)\n  model.train()\n  for batch, (X,y) in enumerate(dataloader):\n    X,y = X.to(device), y.to(device) # I guess we dont actually need the labels\n    pred = model(X)\n    loss = criterion(pred,X) # The difference between X and  the prediction by model\n    with torch.autograd.set_detect_anomaly(False):\n      optimizer.zero_grad()\n      loss.backward()\n      optimizer.step()\n      if batch % 100 == 0:\n        loss,current = loss.item(), batch * len(X)\n        print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n  return loss.item()\n\ndef test(dataloader,model,loss_fn):\n  size = len(dataloader.dataset)\n  num_batches = len(dataloader)\n  model.eval()\n  test_loss, correct = 0,0\n  psnr = 0\n  with torch.no_grad():\n    for X,y in dataloader:\n      X,y = X.to(device), y.to(device)\n      pred = model(X)\n      psnr += compute_psnr(pred.cpu().numpy(),X.cpu().numpy())\n      test_loss += criterion(pred,X).item()\n    print(f\"PSNR: {psnr/num_batches}\")\n    print(f\"Test Loss: {test_loss/num_batches}\")\n\nepochs = 60\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train_loss = train(trainloader, model, criterion, optimizer)\n    test(testloader, model, criterion)\n    scheduler.step(train_loss)\n    # print(f\"The last LR is {scheduler.get_last_lr()[0]}\")\nprint(\"Done!\")","metadata":{"_uuid":"25eb982a-349b-4eb9-a3fc-a5f70efd92d5","_cell_guid":"03ed4f4a-4835-4ce8-b5db-a814680635e1","collapsed":false,"id":"U2j1S9N8RT7J","outputId":"6bdb93f1-5a5b-4979-a4e8-afb25fc574ef","execution":{"iopub.status.busy":"2022-08-05T14:06:16.979926Z","iopub.execute_input":"2022-08-05T14:06:16.980849Z","iopub.status.idle":"2022-08-05T15:23:54.907257Z","shell.execute_reply.started":"2022-08-05T14:06:16.980811Z","shell.execute_reply":"2022-08-05T15:23:54.905212Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Save model\ntorch.save(model.state_dict(), \"model-data_augmented_tanh-coat0.pth\")\nprint(\"Saved PyTorch Model State to model-data_augmented_tanh-coat0.pth\")","metadata":{"_uuid":"4e82de48-6952-4592-8410-64f1c01752e9","_cell_guid":"5d3abe5b-3fac-4b0e-9154-660185ef6ab5","collapsed":false,"id":"ZHRQMNasT0e4","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = MergedAutoEncoder()\nmodel.load_state_dict()","metadata":{"_uuid":"9d68dfce-e182-4e0a-bf3f-aef6e2624cba","_cell_guid":"ce24d3c2-902b-427d-ab25-3e5f34d2d6f3","collapsed":false,"id":"khNjvtG1xYbe","outputId":"a777cf6b-53ae-4823-c244-4e78dd264972","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"_uuid":"db35e004-62e8-4a53-9f22-8c5bd67799a2","_cell_guid":"aec9302d-f4a5-44ad-9e72-882b51db6d28","collapsed":false,"id":"mVomsZXoV6MS","execution":{"iopub.status.busy":"2022-08-05T15:24:10.649064Z","iopub.execute_input":"2022-08-05T15:24:10.649691Z","iopub.status.idle":"2022-08-05T15:24:10.654891Z","shell.execute_reply.started":"2022-08-05T15:24:10.649640Z","shell.execute_reply":"2022-08-05T15:24:10.653883Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for test_images, test_labels in testloader:  \n    sample_image = test_images[0]    \n    sample_label = test_labels[0]","metadata":{"_uuid":"d603d35a-6e2e-4219-bcc4-4ffeaec3188c","_cell_guid":"3390258c-affe-48e2-8cca-b4c5f2cbb806","collapsed":false,"id":"1-35kBV1Wie_","execution":{"iopub.status.busy":"2022-08-05T15:24:13.019273Z","iopub.execute_input":"2022-08-05T15:24:13.019999Z","iopub.status.idle":"2022-08-05T15:24:15.419855Z","shell.execute_reply.started":"2022-08-05T15:24:13.019963Z","shell.execute_reply":"2022-08-05T15:24:15.418573Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(sample_image.reshape(3,32,32).permute(1,2,0))","metadata":{"_uuid":"32e587c0-cfdb-49b0-b5fb-579680082f51","_cell_guid":"d6a70be5-7d2e-47fe-8abf-2f2be43909e3","collapsed":false,"id":"Pr5TZIwtXYUd","execution":{"iopub.status.busy":"2022-08-05T15:24:17.705062Z","iopub.execute_input":"2022-08-05T15:24:17.705582Z","iopub.status.idle":"2022-08-05T15:24:17.929570Z","shell.execute_reply.started":"2022-08-05T15:24:17.705537Z","shell.execute_reply":"2022-08-05T15:24:17.928410Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"724084eb-4435-48e2-9627-c26c3cc222bc","_cell_guid":"ca6d074e-5a95-4efc-8643-ef7f5d44843b","collapsed":false,"id":"fPFUu5-1tge0","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad(): \n  prediction = model(sample_image.unsqueeze(0).to(device))\n  plt.imshow(prediction.cpu().reshape(3,32,32).permute(1,2,0))","metadata":{"_uuid":"63859afb-54c8-45ce-a237-dec70edd27c2","_cell_guid":"2e6f6855-4fcd-4e87-8f2d-c549c4504e2e","collapsed":false,"id":"RwpVoypmZWv1","execution":{"iopub.status.busy":"2022-08-05T15:24:23.891749Z","iopub.execute_input":"2022-08-05T15:24:23.892565Z","iopub.status.idle":"2022-08-05T15:24:24.116135Z","shell.execute_reply.started":"2022-08-05T15:24:23.892525Z","shell.execute_reply":"2022-08-05T15:24:24.115230Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i = 0\nfor train_images, _ in trainloader:  \n    sample_train_image = train_images[0] \n    i += 1\n    if i == 3:\n      break  \nplt.imshow(sample_train_image.reshape(3,32,32).permute(1,2,0))","metadata":{"_uuid":"f1f895bd-5109-40eb-88e3-2f4cedde2121","_cell_guid":"f58f8c25-5b2d-4ab3-9c8e-9722bb2f8666","collapsed":false,"id":"jJ_6TQ0HjylG","outputId":"b66916f8-6489-4281-e64f-8f0b300ea68d","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad(): \n  prediction = model(sample_train_image.unsqueeze(0).to(device))\n  plt.imshow(prediction.cpu().reshape(3,32,32).permute(1,2,0))","metadata":{"_uuid":"a77e092a-8683-4756-a3ac-9c3ae022b6d0","_cell_guid":"2fa81a9e-8eb2-4e1a-9960-4e871e028943","collapsed":false,"id":"kriqPwKikrez","outputId":"2b93db0a-7e73-4207-efcb-1b3e2e6ca227","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Pred: {prediction}, Sample: {sample_train_image}\")","metadata":{"_uuid":"da8fbeaa-38a8-4c88-9aa1-7ca146bc368a","_cell_guid":"cc051bc1-1c31-40fd-892f-666d4f8fbd34","collapsed":false,"id":"fbhoY4b9jBeL","outputId":"3b9ee6fb-543d-4097-d24d-657c74415693","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_train_image[:,1,0]","metadata":{"_uuid":"1eb4c7da-cc60-4896-a9e2-48cc94ef9325","_cell_guid":"e2149836-5601-4f33-b035-34bb5199a61f","collapsed":false,"id":"otSnlnecZotm","outputId":"d4a1a824-3dab-4815-b28f-4e9edc9c902e","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction.cpu().reshape(3,32,32).permute(1,2,0)[1,0,:]","metadata":{"_uuid":"3f6cb1ce-d210-4d51-99bd-0621122f7159","_cell_guid":"36141e08-84bd-4ad3-8f4c-c413e3a34fce","collapsed":false,"id":"jsOjExYqYf1U","outputId":"076199e6-410f-47fa-9566-f32254504da0","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_img = torch.rand((1,3,32,32))\n\nupsampled_test = nn.functional.interpolate(test_img,scale_factor = 2, mode = 'bicubic')\nprint(upsampled_test.shape)","metadata":{"_uuid":"c35b9ce5-c52e-489f-8d2a-0972c8c6792b","_cell_guid":"d84654d0-05df-41bf-aa40-0b195bde433a","collapsed":false,"id":"S-vxnaUqAhA-","outputId":"d57f4ad7-9dfa-4d14-aa90-2202b13ff949","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_img = torch.ones((5,4,3))*0.3\ntest_img[[0,1],:,:] += torch.ones(2,4,3)*0.5\ntest_img[:,:,[0 ,1]] *= -1\nplt.imshow(test_img)\nprint(test_img)","metadata":{"_uuid":"bcf4f697-c05b-4740-bf1b-38b69840a66e","_cell_guid":"adcf78a5-4683-4436-84b2-cd1521c1d2dc","collapsed":false,"id":"-Vabv740gDE2","outputId":"669adc38-1a23-4ca0-d49a-04f7f04df73b","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Transpose Convolution Test","metadata":{"_uuid":"3fa42b9c-bad3-43e2-925f-870a66c64c33","_cell_guid":"0796277c-8f43-4b47-8da6-0402bda4054a","id":"JdVb6oxPu0EX","trusted":true}},{"cell_type":"code","source":"test_img = torch.rand((1,3,4,4))\nconv1 = nn.Conv2d(3,6,9,stride=2,padding = 4)\ntconv1 = nn.ConvTranspose2d(6,3,9,stride=2, padding = 4, padding_mode = 'zeros', output_padding =1)","metadata":{"_uuid":"bdae5c19-78d6-4ded-a6ff-99c6298ec482","_cell_guid":"489d8b32-0b54-4711-ba90-0e50b40a52bd","collapsed":false,"id":"mSu425L3uz3v","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out = conv1(test_img)\nprint(out.shape)","metadata":{"_uuid":"977d13fd-5c86-4d2d-9402-d9d4041a6b94","_cell_guid":"3f1b5b0f-4a8d-4886-a678-143bc0d8aec9","collapsed":false,"id":"HJ0xxACzvc4m","outputId":"de7effd9-8a97-45a8-d728-b294039347fc","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inp = tconv1(out)\nprint(inp,test_img)","metadata":{"_uuid":"d47edd0f-ad11-4cb6-a9ac-c725017ee5d6","_cell_guid":"9ea4b3c2-8a5b-4ea9-bbce-748faacc468a","collapsed":false,"id":"HhtpaPaCvk1v","outputId":"6cc282c2-d00e-4346-f049-eb6b7b3ae4bf","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}