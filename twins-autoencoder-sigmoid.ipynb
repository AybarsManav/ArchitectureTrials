{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7045ec05",
   "metadata": {
    "_cell_guid": "1130a6ce-3175-461a-9c1f-90b79862f8f7",
    "_uuid": "d46a233a-d71a-480c-9614-cea1875dd3dd",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-16T15:50:27.200379Z",
     "iopub.status.busy": "2022-08-16T15:50:27.199409Z",
     "iopub.status.idle": "2022-08-16T15:50:29.198671Z",
     "shell.execute_reply": "2022-08-16T15:50:29.197682Z"
    },
    "id": "OUn97ZAnh6st",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.008615,
     "end_time": "2022-08-16T15:50:29.201665",
     "exception": false,
     "start_time": "2022-08-16T15:50:27.193050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from copy import deepcopy\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from functools import partial\n",
    "from itertools import repeat\n",
    "import collections.abc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103d3a70",
   "metadata": {
    "_cell_guid": "b170ebeb-adce-4cea-a75f-023d531c1e08",
    "_uuid": "0d885729-b83f-45fd-997f-a1d8cfe75ab8",
    "id": "Fnnqzjp5h6sx",
    "papermill": {
     "duration": 0.003401,
     "end_time": "2022-08-16T15:50:29.209088",
     "exception": false,
     "start_time": "2022-08-16T15:50:29.205687",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Prequisite classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad0282c8",
   "metadata": {
    "_cell_guid": "1109fb8d-2a22-494f-8543-f0d1f8129f02",
    "_uuid": "926b9bc2-7778-405b-976b-ee05476653a1",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-16T15:50:29.218837Z",
     "iopub.status.busy": "2022-08-16T15:50:29.217026Z",
     "iopub.status.idle": "2022-08-16T15:50:29.229310Z",
     "shell.execute_reply": "2022-08-16T15:50:29.228422Z"
    },
    "id": "drqPgEtMh6sy",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.018797,
     "end_time": "2022-08-16T15:50:29.231424",
     "exception": false,
     "start_time": "2022-08-16T15:50:29.212627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Mlp(nn.Module):\n",
    "    \"\"\" MLP as used in Vision Transformer, MLP-Mixer and related networks\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, bias=True, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        bias = to_2tuple(bias)\n",
    "        drop_probs = to_2tuple(drop)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features, bias=bias[0])\n",
    "        self.act = act_layer()\n",
    "        self.drop1 = nn.Dropout(drop_probs[0])\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features, bias=bias[1])\n",
    "        self.drop2 = nn.Dropout(drop_probs[1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop2(x)\n",
    "        return x\n",
    "\n",
    "def _ntuple(n):\n",
    "    def parse(x):\n",
    "        if isinstance(x, collections.abc.Iterable) and not isinstance(x, str):\n",
    "            return x\n",
    "        return tuple(repeat(x, n))\n",
    "    return parse\n",
    "\n",
    "to_2tuple = _ntuple(2)\n",
    "\n",
    "class DropPath(nn.Module):\n",
    "    \"\"\"Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).\n",
    "    \"\"\"\n",
    "    def __init__(self, drop_prob: float = 0., scale_by_keep: bool = True):\n",
    "        super(DropPath, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.scale_by_keep = scale_by_keep\n",
    "\n",
    "    def forward(self, x):\n",
    "        return drop_path(x, self.drop_prob, self.training, self.scale_by_keep)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f'drop_prob={round(self.drop_prob,3):0.3f}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b47af31",
   "metadata": {
    "_cell_guid": "91473488-bc47-4a69-871c-66bde8f4c3ff",
    "_uuid": "a29635d2-824b-4b16-a786-0abf3d95191a",
    "id": "-w68QFABHyAb",
    "papermill": {
     "duration": 0.003369,
     "end_time": "2022-08-16T15:50:29.238301",
     "exception": false,
     "start_time": "2022-08-16T15:50:29.234932",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " # **Paper: [Twins Transformer](http://arxiv.org/abs/2104.13840)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb32cf3a",
   "metadata": {
    "_cell_guid": "d1b87cb5-a8f9-449a-b93a-78a397a225aa",
    "_uuid": "9ba31464-2b86-4f4d-a987-fcd94955dd72",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-16T15:50:29.247192Z",
     "iopub.status.busy": "2022-08-16T15:50:29.246917Z",
     "iopub.status.idle": "2022-08-16T15:50:29.304464Z",
     "shell.execute_reply": "2022-08-16T15:50:29.303636Z"
    },
    "id": "NgTgRY0Hh6sz",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.064616,
     "end_time": "2022-08-16T15:50:29.306764",
     "exception": false,
     "start_time": "2022-08-16T15:50:29.242148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Size_ = Tuple[int, int]\n",
    "\n",
    "class LocallyGroupedAttn(nn.Module):\n",
    "    \"\"\" LSA: self attention within a group\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, num_heads=8, attn_drop=0., proj_drop=0., ws=1):\n",
    "        assert ws != 1\n",
    "        super(LocallyGroupedAttn, self).__init__()\n",
    "        assert dim % num_heads == 0, f\"dim {dim} should be divided by num_heads {num_heads}.\"\n",
    "\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = head_dim ** -0.5\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=True)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "        self.ws = ws\n",
    "\n",
    "    def forward(self, x, size: Size_):\n",
    "        # There are two implementations for this function, zero padding or mask. We don't observe obvious difference for\n",
    "        # both. You can choose any one, we recommend forward_padding because it's neat. However,\n",
    "        # the masking implementation is more reasonable and accurate.\n",
    "        B, N, C = x.shape\n",
    "        # x: B,H*W,C\n",
    "        H, W = size\n",
    "        x = x.view(B, H, W, C) # x: B, H ,W , C\n",
    "        pad_l = pad_t = 0\n",
    "        pad_r = (self.ws - W % self.ws) % self.ws\n",
    "        pad_b = (self.ws - H % self.ws) % self.ws\n",
    "        x = F.pad(x, (0, 0, pad_l, pad_r, pad_t, pad_b)) # padds last 3 dimensions, channel by 0,0, height by pad_l, pad_r, width by pad_t, pad_b\n",
    "        # Hp = H + pad_r, Wp = W + pad_b \n",
    "        _, Hp, Wp, _ = x.shape\n",
    "        _h, _w = Hp // self.ws, Wp // self.ws #_h and _w will be the number of the padded smaller windows horizontally and vertically on 2D\n",
    "        x = x.reshape(B, _h, self.ws, _w, self.ws, C).transpose(2, 3) #B,_h,_w,patches in vertical windows, patches in horizontal windows, channels for each patch\n",
    "        #qkv: each of q k v, B, _h*_w, heads, num_windows,  dim_head\n",
    "        qkv = self.qkv(x).reshape(\n",
    "            B, _h * _w, self.ws * self.ws, 3, self.num_heads, C // self.num_heads).permute(3, 0, 1, 4, 2, 5)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2] # q,k,v: B, _h*_w, heads, num_patches, dim_head\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale # attn: B, _h * _w, heads, num_patches,num_patches -- dot product between each patch in each window\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "        attn = (attn @ v).transpose(2, 3).reshape(B, _h, _w, self.ws, self.ws, C) # Attention is done, we get attn: B, _h, _w,  num_patches , num_patches, channels\n",
    "        x = attn.transpose(2, 3).reshape(B, _h * self.ws, _w * self.ws, C) # getting back the whole image again with x: B, padded height, padded width, channels\n",
    "        if pad_r > 0 or pad_b > 0: # If padded somehow, remove the elements in the places of paddings\n",
    "            x = x[:, :H, :W, :].contiguous() # x: B, H, W, C\n",
    "        x = x.reshape(B, N, C) # x: B, H*W, C\n",
    "        x = self.proj(x) #projection of the x tensor to dim channels I DID NOT NDERSTAND WHY EXACTLY\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "    \n",
    "class GlobalSubSampleAttn(nn.Module):\n",
    "    \"\"\" GSA: using a  key to summarize the information for a group to be efficient.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, num_heads=8, attn_drop=0., proj_drop=0., sr_ratio=1):\n",
    "        super().__init__()\n",
    "        assert dim % num_heads == 0, f\"dim {dim} should be divided by num_heads {num_heads}.\"\n",
    "\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = head_dim ** -0.5\n",
    "\n",
    "        self.q = nn.Linear(dim, dim, bias=True)\n",
    "        self.kv = nn.Linear(dim, dim * 2, bias=True)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "        self.sr_ratio = sr_ratio\n",
    "        if sr_ratio > 1:\n",
    "            self.sr = nn.Conv2d(dim, dim, kernel_size=sr_ratio, stride=sr_ratio)\n",
    "            self.norm = nn.LayerNorm(dim)\n",
    "        else:\n",
    "            self.sr = None\n",
    "            self.norm = None\n",
    "\n",
    "    def forward(self, x, size: Size_):\n",
    "        B, N, C = x.shape\n",
    "        q = self.q(x).reshape(B, N, self.num_heads, C // self.num_heads).permute(0, 2, 1, 3) # q: B,num_heads, H*W, head_dim\n",
    "        # We get the queries without supsampling x\n",
    "        if self.sr is not None:\n",
    "            x = x.permute(0, 2, 1).reshape(B, C, *size) # B, C, H, W\n",
    "            x = self.sr(x).reshape(B, C, -1).permute(0, 2, 1) # x: B, C, H/sr, W/sr -> B, C, H/sr*W/sr -- Subsampling\n",
    "            x = self.norm(x)\n",
    "        # After subsampling we get the keys and the values\n",
    "        kv = self.kv(x).reshape(B, -1, 2, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4) # k and v, B, num_heads, H/sr * W/sr, head_dim\n",
    "        k, v = kv[0], kv[1] # k and v : B, num_heads, H/sr * W/sr, head_dim\n",
    "        # q: B,num_heads, H*W, head_dim\n",
    "        # k.transpose(-2,-1) : B, num_heads, head_dim, H/sr * W/sr\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale # attn: B, num_heads, H*W, H/sr * W/sr\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        # attn: B, num_heads, H*W, H/sr * W/sr\n",
    "        # v : B, num_heads, H/sr * W/sr, head_dim\n",
    "        # (attn @ v) : B, num_heads, H*W, head_dim\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C) # x: B, H*W, C == head_dim * num_heads\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self, dim, num_heads, mlp_ratio=4., drop=0., attn_drop=0., drop_path=0.,\n",
    "            act_layer=nn.GELU, norm_layer=nn.LayerNorm, sr_ratio=1, ws=None):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        if ws is None:\n",
    "            self.attn = Attention(dim, num_heads, False, None, attn_drop, drop)\n",
    "        elif ws == 1:\n",
    "            self.attn = GlobalSubSampleAttn(dim, num_heads, attn_drop, drop, sr_ratio)\n",
    "        else:\n",
    "            self.attn = LocallyGroupedAttn(dim, num_heads, attn_drop, drop, ws)\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "\n",
    "    def forward(self, x, size: Size_):\n",
    "        x = x + self.drop_path(self.attn(self.norm1(x), size))\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        return x # x: B, H*W, C\n",
    "    \n",
    "    \n",
    "class PatchMerging(nn.Module):\n",
    "    def __init__(self, dim, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.reduction = nn.Linear(4 * dim, 2 * dim, bias=False)\n",
    "        self.norm = norm_layer(4 * dim)\n",
    "\n",
    "    def forward(self, x, H, W):\n",
    "        \"\"\" Forward function.\n",
    "        Args:\n",
    "            x: Input feature, tensor size (B, H*W, C).\n",
    "            H, W: Spatial resolution of the input feature.\n",
    "        \"\"\"\n",
    "        B, L, C = x.shape\n",
    "        assert L == H * W, \"input feature has wrong size\"\n",
    "\n",
    "        x = x.view(B, H, W, C)\n",
    "\n",
    "        # padding\n",
    "        pad_input = (H % 2 == 1) or (W % 2 == 1)\n",
    "        if pad_input:\n",
    "            x = F.pad(x, (0, 0, 0, W % 2, 0, H % 2))\n",
    "        \n",
    "        # Slice x tensor to 4 patches i.e. each patch has H/2 W/2 height and width.\n",
    "        x0 = x[:, 0::2, 0::2, :]  # B H/2 W/2 C\n",
    "        x1 = x[:, 1::2, 0::2, :]  # B H/2 W/2 C\n",
    "        x2 = x[:, 0::2, 1::2, :]  # B H/2 W/2 C\n",
    "        x3 = x[:, 1::2, 1::2, :]  # B H/2 W/2 C\n",
    "        x = torch.cat([x0, x1, x2, x3], -1)  # B H/2 W/2 4*C -- Concatenate them on channel dim\n",
    "        x = x.view(B, -1, 4 * C)  # B H/2*W/2 4*C\n",
    "\n",
    "        x = self.norm(x)\n",
    "        x = self.reduction(x) \n",
    "        out_size = (H//2 , W//2)\n",
    "        # x: B, H/2 , W/2, 2*C -- resolution down 4 times but channel increased to 2 times\n",
    "        x = x.reshape(B,H//2 * W//2, 2*C)\n",
    "        return x, out_size\n",
    "\n",
    "\n",
    "class PatchSplit(nn.Module):\n",
    "    \"\"\" Patch Merging Layer\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.reduction = nn.Linear(dim, dim * 2, bias=False)\n",
    "        self.norm = norm_layer(dim)\n",
    "        self.shuffle = nn.PixelShuffle(2)\n",
    "\n",
    "    def forward(self, x, H, W):\n",
    "        B, L, C = x.shape\n",
    "        assert L == H * W, \"input feature has wrong size\"\n",
    "        \n",
    "        x = self.norm(x)\n",
    "        x = self.reduction(x)           # B, L, C\n",
    "        x = x.permute(0, 2, 1).contiguous().view(B, 2*C, H, W)\n",
    "        x = self.shuffle(x)             # B, C//2 ,2H, 2W -- With the help of pixelshuffle increases H and W by 2 while decreasing channel\n",
    "        # because we have doubled the channels, after shuffle channels are only halved\n",
    "        x = x.permute(0, 2, 3, 1).contiguous().view(B, 4 * L, -1)\n",
    "        # x: B, 4*H*W, C/2\n",
    "        out_size = (H*2, W*2)\n",
    "        return x, out_size\n",
    "    \n",
    "    \n",
    "class PosConv(nn.Module):\n",
    "    # PEG  from https://arxiv.org/abs/2102.10882\n",
    "    def __init__(self, in_chans, embed_dim=768, stride=1):\n",
    "      # in_chans: Image channels after patch embedding, embed_dim: channels after projection, in_channels must be divisible by embed_dim\n",
    "        super(PosConv, self).__init__()\n",
    "        self.proj = nn.Sequential(nn.Conv2d(in_chans, embed_dim, 3, stride, 1, bias=True, groups=embed_dim), )\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x, size: Size_):\n",
    "        B, N, C = x.shape\n",
    "        cnn_feat_token = x.transpose(1, 2).view(B, C, *size) # cnn_feat_token: B, C, H,W\n",
    "        x = self.proj(cnn_feat_token) # x: B, embed_dim, H,W -- due to stride and size 3 kernel\n",
    "        if self.stride == 1: # Apparently for this to work class PatchEmbed should output an embedding with the same dimensions as PosCov\n",
    "            x += cnn_feat_token\n",
    "        x = x.flatten(2).transpose(1, 2) # x: B, H*W, embed_dim\n",
    "        return x\n",
    "    \n",
    "class PatchEmbed(nn.Module):\n",
    "    \"\"\" Image to Patch Embedding\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768):\n",
    "        super().__init__()\n",
    "        img_size = to_2tuple(img_size) # img_size = (img_size, img_size)\n",
    "        patch_size = to_2tuple(patch_size) # patch_size = (patch_size, patch_size)\n",
    "\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        assert img_size[0] % patch_size[0] == 0 and img_size[1] % patch_size[1] == 0, \\\n",
    "            f\"img_size {img_size} should be divided by patch_size {patch_size}.\"\n",
    "        self.H, self.W = img_size[0] // patch_size[0], img_size[1] // patch_size[1] # H,W: number of patches in vertical and horizontal directions respectively as a 2D map -- Considering each patch as a pixel, H and W makes sense\n",
    "        self.num_patches = self.H * self.W\n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size) # Nonoverlapping convolutions to embed each patch\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x) -> Tuple[torch.Tensor, Size_]:\n",
    "        B, C, H, W = x.shape # Apparently first input is an image with dimensions: B, C, orig_H, orig_W\n",
    "\n",
    "        x = self.proj(x).flatten(2).transpose(1, 2) # x: B, H'*W', embed_dim -- H' and W' are the new image where every pixel is actually a patch with 768 dimensions\n",
    "        x = self.norm(x)\n",
    "        out_size = (H // self.patch_size[0], W // self.patch_size[1])\n",
    "\n",
    "        return x, out_size # Return both the patch embedded x and its new size\n",
    "    \n",
    "class Twins(nn.Module):\n",
    "    \"\"\" Twins Vision Transfomer (Revisiting Spatial Attention)\n",
    "    Adapted from PVT (PyramidVisionTransformer) class at https://github.com/whai362/PVT.git\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, img_size=32, patch_size=2, in_chans=3,\n",
    "            embed_dims=(24,48,96,192), #embed_dims must be increasing by a factor of 2\n",
    "            num_heads=(1, 2, 4, 8), mlp_ratios=(4, 4, 4, 4), depths=(3, 4, 6, 3),\n",
    "            sr_ratios=(8, 4, 2, 1), wss=None, drop_rate=0., attn_drop_rate=0., drop_path_rate=0.,\n",
    "            norm_layer=partial(nn.LayerNorm, eps=1e-6), block_cls=Block):\n",
    "        super().__init__()\n",
    "        self.depths = depths\n",
    "        self.embed_dims = embed_dims\n",
    "        self.num_features = embed_dims[-1]*2\n",
    "        self.grad_checkpointing = False\n",
    "\n",
    "        img_size = to_2tuple(img_size)\n",
    "        prev_chs = in_chans # original image channels\n",
    "      \n",
    "        self.patch_embed = PatchEmbed(img_size = img_size,\n",
    "                                      patch_size = patch_size,\n",
    "                                      in_chans = in_chans,\n",
    "                                      embed_dim = embed_dims[0]\n",
    "                                     )\n",
    "\n",
    "        \n",
    "#         for i in range(len(depths)):\n",
    "#             self.patch_embeds.append(PatchEmbed(img_size, patch_size, prev_chs, embed_dims[i])) # Initilialize the PatchEmbed modules with different embed_dim for each layer\n",
    "#             self.pos_drops.append(nn.Dropout(p=drop_rate))\n",
    "#             prev_chs = embed_dims[i] # Update the prev_chs so we can use PatchEmbed modules\n",
    "#             img_size = tuple(t // patch_size for t in img_size) # Gradual patching, declaring the new img sizes while passing through each layer\n",
    "#             patch_size = 2\n",
    "\n",
    "        self.blocks = nn.ModuleList()\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]  # stochastic depth decay rule\n",
    "        cur = 0\n",
    "        for k in range(len(depths)):\n",
    "            _block = nn.ModuleList([block_cls(\n",
    "                dim=embed_dims[k], num_heads=num_heads[k], mlp_ratio=mlp_ratios[k], drop=drop_rate,\n",
    "                attn_drop=attn_drop_rate, drop_path=dpr[cur + i], norm_layer=norm_layer, sr_ratio=sr_ratios[k],\n",
    "                ws=1 if wss is None or i % 2 == 1 else wss[k]) for i in range(depths[k])]) # In a layer with depth 3 for example the i=0 th layer will do LSA and i = 1 will do GloalSubsampled\n",
    "            self.blocks.append(_block)\n",
    "            cur += depths[k]\n",
    "\n",
    "        self.pos_block = nn.ModuleList([PosConv(embed_dim, embed_dim) for embed_dim in embed_dims])\n",
    "        self.pos_drops = nn.ModuleList([nn.Dropout(p=drop_rate) for i in range(len(depths))])\n",
    "        self.norm = norm_layer(self.num_features)\n",
    "        self.patch_mergers = nn.ModuleList([PatchMerging(embed_dim,norm_layer) for embed_dim in embed_dims])\n",
    "        \n",
    "    def forward(self,x):\n",
    "        B = x.shape[0] # x: B, C, H, W\n",
    "        x, size = self.patch_embed(x) # x: B, Wh * Ww, embed_dim[0] ; size: Wh = H/patch_size , Ww = W/patch_Size\n",
    "        \n",
    "        for i, (merge,drop,blocks,pos_blk) in enumerate(\n",
    "                zip(self.patch_mergers, self.pos_drops, self.blocks, self.pos_block)):\n",
    "            x = drop(x)\n",
    "            for j,blk in enumerate(blocks):\n",
    "                x = blk(x,size)\n",
    "                if j == 0: \n",
    "                    x = pos_blk(x,size) # PEG\n",
    "            \n",
    "            x, size = merge(x,*size) # x: B, Wh/2 * Ww/2, embed_dim[1] for i=0\n",
    "            \n",
    "        x = self.norm(x)\n",
    "        return x \n",
    "        \n",
    "\n",
    "#     def forward(self, x):\n",
    "#         B = x.shape[0]\n",
    "#         for i, (embed, drop, blocks, pos_blk) in enumerate(\n",
    "#                 zip(self.patch_embeds, self.pos_drops, self.blocks, self.pos_block)):\n",
    "#             x, size = embed(x) # First create and embed the patches\n",
    "#             x = drop(x)\n",
    "#             for j, blk in enumerate(blocks): # Pass thorugh attention modules but after the first layer add PEG \n",
    "#                 x = blk(x, size) \n",
    "#                 if j == 0:\n",
    "#                     x = pos_blk(x, size)  # PEG here\n",
    "#             if i < len(self.depths) - 1: # Reshape the x to B, C, H, W unless it is the final output tensor, the final x is x: B, last_H*last_W, last_embedding_dim\n",
    "#                 x = x.reshape(B, *size, -1).permute(0, 3, 1, 2).contiguous()\n",
    "#         x = self.norm(x)\n",
    "#         x = x.reshape(B, *size, -1).permute(0, 3, 1, 2).contiguous()\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79c1d09e",
   "metadata": {
    "_cell_guid": "66ce620b-d92a-4f36-95b4-071731b056d0",
    "_uuid": "7f19ec5e-ab98-4264-ab8b-7fa9c866f102",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-16T15:50:29.315493Z",
     "iopub.status.busy": "2022-08-16T15:50:29.315206Z",
     "iopub.status.idle": "2022-08-16T15:50:29.338105Z",
     "shell.execute_reply": "2022-08-16T15:50:29.337238Z"
    },
    "id": "3iWlBGVZidct",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.029955,
     "end_time": "2022-08-16T15:50:29.340226",
     "exception": false,
     "start_time": "2022-08-16T15:50:29.310271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Inv_PosConv(nn.Module):\n",
    "  def __init__(self,in_chans,embed_dim,stride=1):\n",
    "    super(Inv_PosConv,self).__init__()\n",
    "    self.proj = nn.Sequential(nn.ConvTranspose2d(in_chans, embed_dim, 3, stride, 1, bias=True, groups=embed_dim),)\n",
    "    self.stride = stride\n",
    "\n",
    "  def forward(self,x,size:Size_):\n",
    "    B,N,C = x.shape\n",
    "    # print(x.shape)\n",
    "    cnn_feat_token = x.transpose(1, 2).view(B, C, *size) # cnn_feat_token: B, C, H,W\n",
    "    # print(cnn_feat_token.shape)\n",
    "    x = self.proj(cnn_feat_token) # x: B, embed_dim, H,W -- due to stride and size 3 kernel\n",
    "    # print(x.shape)\n",
    "    if self.stride == 1: # Apparently for this to work class PatchEmbed should output an embedding with the same dimensions as PosCov\n",
    "        x += cnn_feat_token\n",
    "    x = x.flatten(2).transpose(1, 2) # x: B, H*W, embed_dim\n",
    "    return x\n",
    "\n",
    "class Inv_PatchEmbed(nn.Module):\n",
    "  def __init__(self,img_size = 32, patch_size = 2, in_chans = 3 ,embed_dim = 768):\n",
    "    super().__init__()\n",
    "    img_size = to_2tuple(img_size) # img_size = (img_size, img_size)\n",
    "    patch_size = to_2tuple(patch_size) # patch_size = (patch_size, patch_size)\n",
    "\n",
    "    self.img_size = img_size\n",
    "    self.patch_size = patch_size\n",
    "    # assert img_size[0] % patch_size[0] == 0 and img_size[1] % patch_size[1] == 0, \\\n",
    "    #     f\"img_size {img_size} should be divided by patch_size {patch_size}.\"\n",
    "    self.H, self.W = img_size[0] * patch_size[0], img_size[1] * patch_size[1] # H,W: number of patches in vertical and horizontal directions respectively as a 2D map -- Considering each patch as a pixel, H and W makes sense\n",
    "    # self.num_patches = self.H * self.W\n",
    "    self.proj = nn.ConvTranspose2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size) # Nonoverlapping convolutions to embed each patch\n",
    "    self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "  def forward(self, x) -> Tuple[torch.Tensor, Size_]:\n",
    "    B, C, H, W = x.shape # Apparently first input is an image with dimensions: B, C, orig_H, orig_W\n",
    "\n",
    "    x = self.proj(x).flatten(2).transpose(1, 2) # x: B, H'*W', embed_dim -- H' and W' are the new image where every pixel is actually a patch with 768 dimensions\n",
    "    x = self.norm(x)\n",
    "    out_size = (H * self.patch_size[0], W * self.patch_size[1])\n",
    "\n",
    "    return x, out_size # Return both the patch embedded x and its new size\n",
    "\n",
    "\n",
    "\n",
    "class Inv_Twins(nn.Module):\n",
    "    \"\"\" Twins Vision Transfomer (Revisiting Spatial Attention)\n",
    "    Adapted from PVT (PyramidVisionTransformer) class at https://github.com/whai362/PVT.git\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, img_size=1, patch_size=2, in_chans=384, \n",
    "            embed_dims=(192, 96, 48, 24), num_heads=(8,4,2,1), mlp_ratios=(4, 4, 4, 4), depths=(3, 6, 4, 3),\n",
    "            sr_ratios=(1,2,4,8), wss=None, drop_rate=0., attn_drop_rate=0., drop_path_rate=0.,\n",
    "            norm_layer=partial(nn.LayerNorm, eps=1e-6), block_cls=Block):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.size = to_2tuple(img_size)\n",
    "        self.depths = depths\n",
    "        self.embed_dims = embed_dims\n",
    "        self.num_features = embed_dims[-1]\n",
    "        self.grad_checkpointing = False\n",
    "        self.embed_dims = embed_dims\n",
    "\n",
    "        img_size = to_2tuple(img_size)\n",
    "        prev_chs = in_chans # channels of the output from the encoder\n",
    "      \n",
    "      \n",
    "        \n",
    "\n",
    "        self.blocks = nn.ModuleList()\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]  # stochastic depth decay rule\n",
    "        cur = 0\n",
    "        for k in range(len(depths)):\n",
    "            _block = nn.ModuleList([block_cls(\n",
    "                dim=embed_dims[k], num_heads=num_heads[k], mlp_ratio=mlp_ratios[k], drop=drop_rate,\n",
    "                attn_drop=attn_drop_rate, drop_path=dpr[cur + i], norm_layer=norm_layer, sr_ratio=sr_ratios[k],\n",
    "                ws=1 if wss is None or i % 2 == 1 else wss[k]) for i in range(depths[k])]) # In a layer with depth 3 for example the i=0 th layer will do LSA and i = 1 will do GloalSubsampled\n",
    "            self.blocks.append(_block)\n",
    "            cur += depths[k]\n",
    "\n",
    "        self.pos_block = nn.ModuleList([PosConv(embed_dim, embed_dim) for embed_dim in embed_dims])\n",
    "        self.pos_drops = nn.ModuleList([nn.Dropout(p=drop_rate) for i in range(len(depths))])\n",
    "        self.norm = norm_layer(self.num_features)\n",
    "        self.patch_splitters = nn.ModuleList([PatchSplit(embed_dim * 2,norm_layer) for embed_dim in embed_dims])\n",
    "        self.de_embed = nn.Sequential(nn.Conv2d(embed_dims[-1],embed_dims[-1] * patch_size ** 2, kernel_size=5, stride=1, padding=2),\n",
    "                                      nn.PixelShuffle(patch_size),\n",
    "                                      nn.Conv2d(embed_dims[-1], 3, kernel_size=3, stride=1, padding=1))\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "      B = x.shape[0] # x: B, H*W , in_chans\n",
    "      size = self.size\n",
    "      for i, (split, drop, blocks, pos_blk) in enumerate(\n",
    "              zip(self.patch_splitters, self.pos_drops, self.blocks, self.pos_block)):\n",
    "        x, size = split(x,*size) # for i = 0, x: B, H*W*4 , in_chans/2 == embed_dim[0]\n",
    "        x = drop(x)\n",
    "        for j, blk in enumerate(blocks):\n",
    "            x = blk(x,size)\n",
    "            if j == 0:\n",
    "              x = pos_blk(x,size) # PEG\n",
    "      x = self.norm(x) # x: B, initial_H/2 * initial_W/2 , embed_dims[-1]\n",
    "      x = self.de_embed(x.view(-1,*size,self.embed_dims[-1]).permute(0,3,1,2).contiguous())\n",
    "      return x\n",
    "\n",
    "\n",
    "    # def forward(self, x):\n",
    "    #     B = x.shape[0] # x: B,H,W,C\n",
    "    #     for i, (inv_embed, drop, blocks, pos_blk) in enumerate(\n",
    "    #             zip(self.patch_embeds, self.pos_drops, self.blocks, self.pos_block)):\n",
    "    #         x, size = inv_embed(x) # First create and embed the patches -- B,H*2,W*2, embed_dim[0] ->\n",
    "    #         # print(size)\n",
    "    #         x = drop(x)\n",
    "    #         for j, blk in enumerate(blocks): # Pass thorugh attention modules but after the first layer add PEG \n",
    "    #             x = blk(x, size)  # x: B,H*2,W*2,embed_dim[0]\n",
    "    #             if j == 0:\n",
    "    #                 x = pos_blk(x, size)  # x: B,H*2,W*2,embed_dim[0]\n",
    "    #         if i < len(self.depths) - 1: # Reshape the x to B, C, H, W unless it is the final output tensor, the final x is x: B, last_H*last_W, last_embedding_dim\n",
    "    #             x = x.reshape(B, *size, -1).permute(0, 3, 1, 2).contiguous()\n",
    "    #     x = self.norm(x)\n",
    "    #     x = x.reshape(B, *size, -1).contiguous()\n",
    "    #     x = self.proj(x)\n",
    "    #     x = self.act(x)\n",
    "    #     x = x.reshape(B,-1,*size)\n",
    "\n",
    "    #     return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee6957c2",
   "metadata": {
    "_cell_guid": "90d298b4-c3bf-4f94-b16c-70ed6a1e50ee",
    "_uuid": "0b618569-d4f1-427a-a8f1-21b034b2d791",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-16T15:50:29.348570Z",
     "iopub.status.busy": "2022-08-16T15:50:29.348283Z",
     "iopub.status.idle": "2022-08-16T15:50:29.354197Z",
     "shell.execute_reply": "2022-08-16T15:50:29.353311Z"
    },
    "id": "dc5by9JPh6s1",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.012355,
     "end_time": "2022-08-16T15:50:29.356250",
     "exception": false,
     "start_time": "2022-08-16T15:50:29.343895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MergedAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MergedAutoEncoder,self).__init__()\n",
    "        ########## encoder #########\n",
    "        self.encoder = Twins(wss=(2,2,2,2))\n",
    "        self.decoder = Inv_Twins(wss=(2,2,2,2))\n",
    "    \n",
    "    def encode(self,x):\n",
    "            x = self.encoder(x)\n",
    "            return x\n",
    "    \n",
    "    def decode(self,x):\n",
    "      x = self.decoder(x)\n",
    "      return x\n",
    "        \n",
    "    def forward(self,x):\n",
    "            x = self.encode(x)\n",
    "            x = self.decode(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f498ab3",
   "metadata": {
    "_cell_guid": "50f341f5-9405-4b85-b4c4-f621d71f33f9",
    "_uuid": "45ccad17-3ba3-4560-ae06-acd3e7d21ea2",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-16T15:50:29.365084Z",
     "iopub.status.busy": "2022-08-16T15:50:29.364254Z",
     "iopub.status.idle": "2022-08-16T16:51:33.412268Z",
     "shell.execute_reply": "2022-08-16T16:51:33.411064Z"
    },
    "id": "kiM5JxfHiSL3",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3664.072228,
     "end_time": "2022-08-16T16:51:33.431972",
     "exception": false,
     "start_time": "2022-08-16T15:50:29.359744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9219f12b0645bb8919646373f57f2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.340039  [    0/50000]\n",
      "loss: 0.057232  [12800/50000]\n",
      "loss: 0.044979  [25600/50000]\n",
      "loss: 0.029983  [38400/50000]\n",
      "PSNR: 16.35454365437104\n",
      "Test Loss: 0.023177176973299136\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.022669  [    0/50000]\n",
      "loss: 0.020093  [12800/50000]\n",
      "loss: 0.019899  [25600/50000]\n",
      "loss: 0.017452  [38400/50000]\n",
      "PSNR: 17.810444142746896\n",
      "Test Loss: 0.016576959586501877\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.016621  [    0/50000]\n",
      "loss: 0.016556  [12800/50000]\n",
      "loss: 0.013976  [25600/50000]\n",
      "loss: 0.013720  [38400/50000]\n",
      "PSNR: 18.766076012311714\n",
      "Test Loss: 0.013300811023085932\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.013275  [    0/50000]\n",
      "loss: 0.012399  [12800/50000]\n",
      "loss: 0.011379  [25600/50000]\n",
      "loss: 0.012047  [38400/50000]\n",
      "PSNR: 19.13683093060747\n",
      "Test Loss: 0.012211274414594415\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.012040  [    0/50000]\n",
      "loss: 0.012320  [12800/50000]\n",
      "loss: 0.010935  [25600/50000]\n",
      "loss: 0.011190  [38400/50000]\n",
      "PSNR: 19.587609109801612\n",
      "Test Loss: 0.011007815623019316\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.011228  [    0/50000]\n",
      "loss: 0.011228  [12800/50000]\n",
      "loss: 0.010255  [25600/50000]\n",
      "loss: 0.011353  [38400/50000]\n",
      "PSNR: 19.92767447868851\n",
      "Test Loss: 0.010179501074024393\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.010462  [    0/50000]\n",
      "loss: 0.009528  [12800/50000]\n",
      "loss: 0.009439  [25600/50000]\n",
      "loss: 0.010099  [38400/50000]\n",
      "PSNR: 19.36439938351992\n",
      "Test Loss: 0.011584932408943961\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.011897  [    0/50000]\n",
      "loss: 0.010144  [12800/50000]\n",
      "loss: 0.009671  [25600/50000]\n",
      "loss: 0.009438  [38400/50000]\n",
      "PSNR: 20.379840102002696\n",
      "Test Loss: 0.009172995433305638\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.009346  [    0/50000]\n",
      "loss: 0.010565  [12800/50000]\n",
      "loss: 0.008169  [25600/50000]\n",
      "loss: 0.008199  [38400/50000]\n",
      "PSNR: 20.636394010474252\n",
      "Test Loss: 0.008646473600941746\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.008518  [    0/50000]\n",
      "loss: 0.008774  [12800/50000]\n",
      "loss: 0.009350  [25600/50000]\n",
      "loss: 0.007615  [38400/50000]\n",
      "PSNR: 20.77780631836338\n",
      "Test Loss: 0.00836898599267949\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.007701  [    0/50000]\n",
      "loss: 0.008576  [12800/50000]\n",
      "loss: 0.007580  [25600/50000]\n",
      "loss: 0.007537  [38400/50000]\n",
      "PSNR: 20.97967127462117\n",
      "Test Loss: 0.007988998613355659\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.008212  [    0/50000]\n",
      "loss: 0.008002  [12800/50000]\n",
      "loss: 0.008675  [25600/50000]\n",
      "loss: 0.007832  [38400/50000]\n",
      "PSNR: 21.24266075139634\n",
      "Test Loss: 0.0075198761423271665\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.007627  [    0/50000]\n",
      "loss: 0.007831  [12800/50000]\n",
      "loss: 0.006971  [25600/50000]\n",
      "loss: 0.007077  [38400/50000]\n",
      "PSNR: 21.431110055553365\n",
      "Test Loss: 0.007200765735882369\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.007489  [    0/50000]\n",
      "loss: 0.007165  [12800/50000]\n",
      "loss: 0.007272  [25600/50000]\n",
      "loss: 0.006370  [38400/50000]\n",
      "PSNR: 21.601997306551606\n",
      "Test Loss: 0.006922883093592864\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.006912  [    0/50000]\n",
      "loss: 0.006620  [12800/50000]\n",
      "loss: 0.006467  [25600/50000]\n",
      "loss: 0.007365  [38400/50000]\n",
      "PSNR: 21.77165647967015\n",
      "Test Loss: 0.0066576919435888905\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.006686  [    0/50000]\n",
      "loss: 0.006601  [12800/50000]\n",
      "loss: 0.006683  [25600/50000]\n",
      "loss: 0.006761  [38400/50000]\n",
      "PSNR: 21.58292084189759\n",
      "Test Loss: 0.006952435302819255\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.006802  [    0/50000]\n",
      "loss: 0.006664  [12800/50000]\n",
      "loss: 0.006328  [25600/50000]\n",
      "loss: 0.006342  [38400/50000]\n",
      "PSNR: 22.0165024771402\n",
      "Test Loss: 0.0062927585861445225\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.006314  [    0/50000]\n",
      "loss: 0.006742  [12800/50000]\n",
      "loss: 0.006435  [25600/50000]\n",
      "loss: 0.006136  [38400/50000]\n",
      "PSNR: 22.14115871290306\n",
      "Test Loss: 0.006114707399112514\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.006158  [    0/50000]\n",
      "loss: 0.006403  [12800/50000]\n",
      "loss: 0.006113  [25600/50000]\n",
      "loss: 0.005587  [38400/50000]\n",
      "PSNR: 21.815355234542203\n",
      "Test Loss: 0.006589547571832243\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.006752  [    0/50000]\n",
      "loss: 0.006193  [12800/50000]\n",
      "loss: 0.007959  [25600/50000]\n",
      "loss: 0.005505  [38400/50000]\n",
      "PSNR: 22.44595673750569\n",
      "Test Loss: 0.005700236669729782\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.005355  [    0/50000]\n",
      "loss: 0.005658  [12800/50000]\n",
      "loss: 0.005947  [25600/50000]\n",
      "loss: 0.005030  [38400/50000]\n",
      "PSNR: 22.635200229946154\n",
      "Test Loss: 0.005457202780142992\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.005099  [    0/50000]\n",
      "loss: 0.006312  [12800/50000]\n",
      "loss: 0.005306  [25600/50000]\n",
      "loss: 0.005693  [38400/50000]\n",
      "PSNR: 22.71239653687898\n",
      "Test Loss: 0.005360967750790753\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.005876  [    0/50000]\n",
      "loss: 0.005472  [12800/50000]\n",
      "loss: 0.005200  [25600/50000]\n",
      "loss: 0.005563  [38400/50000]\n",
      "PSNR: 22.81914378626606\n",
      "Test Loss: 0.00523083032804388\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.005049  [    0/50000]\n",
      "loss: 0.005167  [12800/50000]\n",
      "loss: 0.004958  [25600/50000]\n",
      "loss: 0.005194  [38400/50000]\n",
      "PSNR: 23.020699922394925\n",
      "Test Loss: 0.004993857061372528\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.004996  [    0/50000]\n",
      "loss: 0.004959  [12800/50000]\n",
      "loss: 0.005146  [25600/50000]\n",
      "loss: 0.004497  [38400/50000]\n",
      "PSNR: 23.153505124217233\n",
      "Test Loss: 0.00484343802061262\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.004425  [    0/50000]\n",
      "loss: 0.004590  [12800/50000]\n",
      "loss: 0.004369  [25600/50000]\n",
      "loss: 0.004739  [38400/50000]\n",
      "PSNR: 23.27908920635269\n",
      "Test Loss: 0.004705377518423373\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.004753  [    0/50000]\n",
      "loss: 0.004617  [12800/50000]\n",
      "loss: 0.004659  [25600/50000]\n",
      "loss: 0.004438  [38400/50000]\n",
      "PSNR: 23.346449902337813\n",
      "Test Loss: 0.004632905744534882\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.004965  [    0/50000]\n",
      "loss: 0.004357  [12800/50000]\n",
      "loss: 0.004572  [25600/50000]\n",
      "loss: 0.004678  [38400/50000]\n",
      "PSNR: 23.446493768767272\n",
      "Test Loss: 0.004527335615144877\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.004598  [    0/50000]\n",
      "loss: 0.004532  [12800/50000]\n",
      "loss: 0.004218  [25600/50000]\n",
      "loss: 0.004380  [38400/50000]\n",
      "PSNR: 23.633116010764503\n",
      "Test Loss: 0.004337159598458417\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.004121  [    0/50000]\n",
      "loss: 0.004243  [12800/50000]\n",
      "loss: 0.004675  [25600/50000]\n",
      "loss: 0.003901  [38400/50000]\n",
      "PSNR: 23.571930435037633\n",
      "Test Loss: 0.004398354691677267\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.004556  [    0/50000]\n",
      "loss: 0.004743  [12800/50000]\n",
      "loss: 0.004687  [25600/50000]\n",
      "loss: 0.004189  [38400/50000]\n",
      "PSNR: 23.76870553491233\n",
      "Test Loss: 0.00420382020323054\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.004085  [    0/50000]\n",
      "loss: 0.004789  [12800/50000]\n",
      "loss: 0.004229  [25600/50000]\n",
      "loss: 0.004128  [38400/50000]\n",
      "PSNR: 23.75961481913283\n",
      "Test Loss: 0.004212562436874532\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.004050  [    0/50000]\n",
      "loss: 0.004203  [12800/50000]\n",
      "loss: 0.004270  [25600/50000]\n",
      "loss: 0.004386  [38400/50000]\n",
      "PSNR: 23.871786323478158\n",
      "Test Loss: 0.004105303704715039\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.003849  [    0/50000]\n",
      "loss: 0.004067  [12800/50000]\n",
      "loss: 0.004054  [25600/50000]\n",
      "loss: 0.004048  [38400/50000]\n",
      "PSNR: 23.958117864709696\n",
      "Test Loss: 0.00402452353729949\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.004124  [    0/50000]\n",
      "loss: 0.003744  [12800/50000]\n",
      "loss: 0.003839  [25600/50000]\n",
      "loss: 0.004049  [38400/50000]\n",
      "PSNR: 23.982721500156384\n",
      "Test Loss: 0.004001701745805861\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.003867  [    0/50000]\n",
      "loss: 0.004157  [12800/50000]\n",
      "loss: 0.003661  [25600/50000]\n",
      "loss: 0.003672  [38400/50000]\n",
      "PSNR: 24.066537551436085\n",
      "Test Loss: 0.003925252372776217\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.004234  [    0/50000]\n",
      "loss: 0.003936  [12800/50000]\n",
      "loss: 0.004056  [25600/50000]\n",
      "loss: 0.004121  [38400/50000]\n",
      "PSNR: 23.81995972903548\n",
      "Test Loss: 0.004153978565849269\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.004067  [    0/50000]\n",
      "loss: 0.003738  [12800/50000]\n",
      "loss: 0.004264  [25600/50000]\n",
      "loss: 0.003642  [38400/50000]\n",
      "PSNR: 24.116422070447392\n",
      "Test Loss: 0.003880473546377277\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.003791  [    0/50000]\n",
      "loss: 0.003775  [12800/50000]\n",
      "loss: 0.003875  [25600/50000]\n",
      "loss: 0.003595  [38400/50000]\n",
      "PSNR: 24.26921652237514\n",
      "Test Loss: 0.00374639844757658\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.003536  [    0/50000]\n",
      "loss: 0.003935  [12800/50000]\n",
      "loss: 0.003931  [25600/50000]\n",
      "loss: 0.003874  [38400/50000]\n",
      "PSNR: 24.29620938154533\n",
      "Test Loss: 0.0037231588724387595\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.003694  [    0/50000]\n",
      "loss: 0.003732  [12800/50000]\n",
      "loss: 0.003396  [25600/50000]\n",
      "loss: 0.003685  [38400/50000]\n",
      "PSNR: 24.36769067154165\n",
      "Test Loss: 0.0036623943626550555\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.003446  [    0/50000]\n",
      "loss: 0.003727  [12800/50000]\n",
      "loss: 0.003572  [25600/50000]\n",
      "loss: 0.003365  [38400/50000]\n",
      "PSNR: 24.35785437567221\n",
      "Test Loss: 0.0036706834400803607\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.003813  [    0/50000]\n",
      "loss: 0.003582  [12800/50000]\n",
      "loss: 0.003642  [25600/50000]\n",
      "loss: 0.003275  [38400/50000]\n",
      "PSNR: 24.471891136813436\n",
      "Test Loss: 0.0035755558387388156\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.003514  [    0/50000]\n",
      "loss: 0.003472  [12800/50000]\n",
      "loss: 0.004555  [25600/50000]\n",
      "loss: 0.003465  [38400/50000]\n",
      "PSNR: 24.520071639705936\n",
      "Test Loss: 0.003536115818998859\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.003450  [    0/50000]\n",
      "loss: 0.003522  [12800/50000]\n",
      "loss: 0.003485  [25600/50000]\n",
      "loss: 0.003363  [38400/50000]\n",
      "PSNR: 24.520106257912808\n",
      "Test Loss: 0.0035359954337671963\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.003919  [    0/50000]\n",
      "loss: 0.003607  [12800/50000]\n",
      "loss: 0.003355  [25600/50000]\n",
      "loss: 0.003315  [38400/50000]\n",
      "PSNR: 24.621058714830248\n",
      "Test Loss: 0.0034548523953726773\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.003455  [    0/50000]\n",
      "loss: 0.003380  [12800/50000]\n",
      "loss: 0.003642  [25600/50000]\n",
      "loss: 0.003142  [38400/50000]\n",
      "PSNR: 24.557278074890753\n",
      "Test Loss: 0.003505825374534802\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.003384  [    0/50000]\n",
      "loss: 0.003734  [12800/50000]\n",
      "loss: 0.003437  [25600/50000]\n",
      "loss: 0.003453  [38400/50000]\n",
      "PSNR: 24.440446461346436\n",
      "Test Loss: 0.003601003724114993\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.003768  [    0/50000]\n",
      "loss: 0.003984  [12800/50000]\n",
      "loss: 0.003465  [25600/50000]\n",
      "loss: 0.003315  [38400/50000]\n",
      "PSNR: 24.781067683937266\n",
      "Test Loss: 0.003329906762943049\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.003348  [    0/50000]\n",
      "loss: 0.003490  [12800/50000]\n",
      "loss: 0.003440  [25600/50000]\n",
      "loss: 0.003440  [38400/50000]\n",
      "PSNR: 24.83904956303802\n",
      "Test Loss: 0.00328573881636692\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.003226  [    0/50000]\n",
      "loss: 0.004116  [12800/50000]\n",
      "loss: 0.003284  [25600/50000]\n",
      "loss: 0.003179  [38400/50000]\n",
      "PSNR: 24.93801286039904\n",
      "Test Loss: 0.0032117630537787946\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.003133  [    0/50000]\n",
      "loss: 0.003133  [12800/50000]\n",
      "loss: 0.003035  [25600/50000]\n",
      "loss: 0.003234  [38400/50000]\n",
      "PSNR: 24.61795369647172\n",
      "Test Loss: 0.003456919810652167\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.003269  [    0/50000]\n",
      "loss: 0.003235  [12800/50000]\n",
      "loss: 0.003426  [25600/50000]\n",
      "loss: 0.003359  [38400/50000]\n",
      "PSNR: 25.032685310421762\n",
      "Test Loss: 0.003142508038590792\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.003090  [    0/50000]\n",
      "loss: 0.002924  [12800/50000]\n",
      "loss: 0.002991  [25600/50000]\n",
      "loss: 0.003137  [38400/50000]\n",
      "PSNR: 24.9505327516047\n",
      "Test Loss: 0.003202262508411762\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.003395  [    0/50000]\n",
      "loss: 0.003051  [12800/50000]\n",
      "loss: 0.002865  [25600/50000]\n",
      "loss: 0.002920  [38400/50000]\n",
      "PSNR: 25.13005929113808\n",
      "Test Loss: 0.003072849919878041\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.003090  [    0/50000]\n",
      "loss: 0.002995  [12800/50000]\n",
      "loss: 0.002859  [25600/50000]\n",
      "loss: 0.002910  [38400/50000]\n",
      "PSNR: 25.17262250002153\n",
      "Test Loss: 0.0030428596766359068\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.003021  [    0/50000]\n",
      "loss: 0.002937  [12800/50000]\n",
      "loss: 0.003020  [25600/50000]\n",
      "loss: 0.003057  [38400/50000]\n",
      "PSNR: 25.231261811771223\n",
      "Test Loss: 0.0030020425550026605\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.003263  [    0/50000]\n",
      "loss: 0.003070  [12800/50000]\n",
      "loss: 0.002799  [25600/50000]\n",
      "loss: 0.003103  [38400/50000]\n",
      "PSNR: 25.249998444933688\n",
      "Test Loss: 0.0029890749137848616\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.003044  [    0/50000]\n",
      "loss: 0.002896  [12800/50000]\n",
      "loss: 0.002979  [25600/50000]\n",
      "loss: 0.002933  [38400/50000]\n",
      "PSNR: 25.31378847356659\n",
      "Test Loss: 0.0029455031462815367\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.002796  [    0/50000]\n",
      "loss: 0.003170  [12800/50000]\n",
      "loss: 0.002765  [25600/50000]\n",
      "loss: 0.002949  [38400/50000]\n",
      "PSNR: 25.381653483235457\n",
      "Test Loss: 0.002899863182484538\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.modules import loss\n",
    "from torchvision.transforms.transforms import RandomVerticalFlip\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "#      transforms.RandomHorizontalFlip(p=0.5),\n",
    "#      transforms.RandomCrop(32,padding=4),\n",
    "#      transforms.RandomVerticalFlip(p=0.5),\n",
    "     transforms.ToTensor(),\n",
    "#      transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
    "    ])# normalize the image between [-1 1]\n",
    "\n",
    "test_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "#      transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
    "    ])\n",
    "\n",
    "batch_size = 128\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=train_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=test_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "model = MergedAutoEncoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='max',patience=2,verbose=True,factor = 0.80)\n",
    "\n",
    "def compute_psnr(img1, img2):\n",
    "    img1 = img1.astype(np.float64) \n",
    "    img2 = img2.astype(np.float64) \n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return \"Same Image\"\n",
    "    return 10 * math.log10(1. / mse)\n",
    "\n",
    "######## Training #########\n",
    "def train(dataloader,model,loss_fn,optimizer):\n",
    "  size = len(dataloader.dataset)\n",
    "  model.train()\n",
    "  for batch, (X,y) in enumerate(dataloader):\n",
    "    X = X.to(device) \n",
    "    pred = model(X)\n",
    "    loss = criterion(pred,X) # The difference between X and  the prediction by model\n",
    "    with torch.autograd.set_detect_anomaly(False):\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      if batch % 100 == 0:\n",
    "        loss,current = loss.item(), batch * len(X)\n",
    "        print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader,model,loss_fn):\n",
    "  size = len(dataloader.dataset)\n",
    "  num_batches = len(dataloader)\n",
    "  model.eval()\n",
    "  test_loss, correct = 0,0\n",
    "  psnr = 0\n",
    "  with torch.no_grad():\n",
    "    for X,y in dataloader:\n",
    "      X = X.to(device)\n",
    "      pred = model(X)\n",
    "      psnr += compute_psnr(pred.cpu().numpy(),X.cpu().numpy())\n",
    "      test_loss += criterion(pred,X).item()\n",
    "    print(f\"PSNR: {psnr/num_batches}\")\n",
    "    print(f\"Test Loss: {test_loss/num_batches}\")\n",
    "  return psnr/num_batches\n",
    "\n",
    "epochs = 60\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(trainloader, model, criterion, optimizer)\n",
    "    PSNR = test(testloader, model, criterion)\n",
    "    scheduler.step(PSNR)\n",
    "    # print(f\"The last LR is {scheduler.get_last_lr()[0]}\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9123139b",
   "metadata": {
    "_cell_guid": "f5dd57cf-38c8-45bd-9fd7-22c3181abeb3",
    "_uuid": "e8a57815-46fd-478e-8752-3e14f8350b56",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-16T16:51:33.470154Z",
     "iopub.status.busy": "2022-08-16T16:51:33.469828Z",
     "iopub.status.idle": "2022-08-16T16:51:33.475050Z",
     "shell.execute_reply": "2022-08-16T16:51:33.474047Z"
    },
    "id": "i9aE5EDvD2T9",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.02692,
     "end_time": "2022-08-16T16:51:33.477197",
     "exception": false,
     "start_time": "2022-08-16T16:51:33.450277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Save model\n",
    "# torch.save(model.state_dict(), \"model-Twins_Autoencoder_sigmoid.pth\")\n",
    "# print(\"Saved PyTorch Model State to model-Twins_Autoencoder_sigmoid.pth\")\n",
    "# from google.colab import files\n",
    "# files.download( \"model-Twins_Autoencoder.pth\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5c57575",
   "metadata": {
    "_cell_guid": "724b0cb2-a5f5-4ea6-808c-8fc223c4c9db",
    "_uuid": "f1afef46-d3ca-4b07-bcfe-193aef7b3273",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-16T16:51:33.514290Z",
     "iopub.status.busy": "2022-08-16T16:51:33.514016Z",
     "iopub.status.idle": "2022-08-16T16:51:33.909596Z",
     "shell.execute_reply": "2022-08-16T16:51:33.908538Z"
    },
    "id": "nPBdGhM4DqQg",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.416897,
     "end_time": "2022-08-16T16:51:33.912064",
     "exception": false,
     "start_time": "2022-08-16T16:51:33.495167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6a1717ded0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for test_images, _ in testloader:\n",
    "    sample_image = test_images[2]\n",
    "    break;\n",
    "plt.imshow(sample_image.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87f007a3",
   "metadata": {
    "_cell_guid": "86130a2a-1406-4785-a12c-dc739770b941",
    "_uuid": "a39ff822-7e1b-47d2-9100-ff3961733f34",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-16T16:51:33.951537Z",
     "iopub.status.busy": "2022-08-16T16:51:33.951222Z",
     "iopub.status.idle": "2022-08-16T16:51:34.165248Z",
     "shell.execute_reply": "2022-08-16T16:51:34.164280Z"
    },
    "id": "hCfjlHYMHyAi",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.236287,
     "end_time": "2022-08-16T16:51:34.167437",
     "exception": false,
     "start_time": "2022-08-16T16:51:33.931150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAc6klEQVR4nO2dbYxkZ3Xn/+feeu3uefGM7WEYnJiwSCsUJQaNLFZBiBAReVEkgxQh+ID8AWWiVZAWKfvBIlIg0n4gqwDiw4rVEKw4EeFlAwhrhXbDWpFQPqyhYY0xOFkcy8Yez4tnenqmq7ve7r0nH6q8GlvP/3R7urt64Pn/pNFU31PPvec+dU/dqudf5xxzdwghfvkpDtoBIcRiULALkQkKdiEyQcEuRCYo2IXIBAW7EJnQ2s1gM7sPwOcAlAD+0t0/FT3/8NFjfuJ1p5K2umnouCawMcpWyW0lP20zvs+CGA18ULS/GC6JRru0gvkYHMmD+Q2kWQtOrijS95HQj8AWDYzmn7vPj3azavTNv9Z7x/M//zmuXLmc9OSmg93MSgD/FcB7ALwA4Ptm9oi7/5SNOfG6U/jMQ99K2gabm/RYW8NRcnt0kd527Ai1HT5yjNo6bf4m0Wm1yXb+AalVRgERXFVNzfcZXNy9Xtr/lnEfq+mQ2yYTauv3O9yPTi/tR8Ffs2n0Btfi51x6+nUBAG/S+6zIdgCoqoofi7yJAUCr5DY3/noWxNREb2Jkrt7z7nfy41DL9twL4Gl3f8bdJwC+AuD+XexPCLGP7CbYTwF4/oa/X5hvE0Lcguz7Ap2ZnTGzVTNbvba+tt+HE0IQdhPs5wDcdcPfb5hvewXuftbdT7v76SNH+XdlIcT+sptg/z6AN5vZG82sA+CDAB7ZG7eEEHvNTa/Gu3tlZh8F8L8wk94ecvefbDeOySTR6uiYrAhHct3haDU7Wtkt+Wq8Wfp4JZG7tjtWEWg8lfMV4aLgPva6/eT2brBSPAlUgSqQk1aWVqhtuZe+tKqGn5dNp9RWBvelIji3hk1VcO04v3QQvJzodrkqYA0fWBOFokXUHwCoq7STTB4Gdqmzu/u3AXx7N/sQQiwG/YJOiExQsAuRCQp2ITJBwS5EJijYhciEXa3Gv1aKssDySloaGo7SyS4AsEnUhEDxQjuQp6KTLqMMMCIP8iMBLQQ6Th0kR/iY24IjtqxLxvCzDnJ/gCB7sB3oUObp+8jWFk94Wl9f5260edLN0cOHqa1k4yJ9LbBZkAjjdZC56VxWrOr0dVVEF3ggNzJ0ZxciExTsQmSCgl2ITFCwC5EJCnYhMmGxq/FmWOqkD9lf4q70yXJ8PeWrn21W6wdAp+S2MrC1SPJEu+C+t6LKasGxioavxrfISjcANNO0L3WgTjRBGaZqym3DMV8tHiO96n7x/AU65vyLz1Nb2UuXuQKAkydfT223H7s9ud2CUmKIyoUFq+r1hNs8qqNoZI6DkmazqnDJI9ExurMLkQkKdiEyQcEuRCYo2IXIBAW7EJmgYBciExYqvQGOgiSGlDXvPGKkY0kz3grGLFFbu+G10zpRDbpWWj7hohDQsajNEJfXKuPzEeVw1CNiDOTBadSYZhrcD4K6gU6krSqQoLZGQQ264FjTSNZqp/3otdMJQwDQKvjrEtWuq4JkrnrKbQ2R0drtKHnptbf50p1diExQsAuRCQp2ITJBwS5EJijYhcgEBbsQmbAr6c3MngWwAaAGULn76XCAO5UgfBLIFkRia0a8nlkxHnBbdYjaykCiKklGUVGlpUEgrkvmkYZWcRkqSqQbkbmqg0y5OroMjNuKfpDt16RbF02DunvToB2WBe2wxmMuU1bjtIxWB5ltraj2WzD3VgZttCp+HVidPjePem/RjLjgvPjedsxvu/vlPdiPEGIf0cd4ITJht8HuAP7ezH5gZmf2wiEhxP6w24/x73D3c2Z2J4DvmNk/uft3b3zC/E3gDAC87uSpXR5OCHGz7OrO7u7n5v9fAvBNAPcmnnPW3U+7++mjtx3bzeGEELvgpoPdzJbN7NDLjwH8LoAn98oxIcTespuP8ScAfNPMXt7P37r7/4wGmAEtIk90eXcfdEm2WafL36s6aeUHANBiBf4AtIN2TaWn5Y6gCxIsaCdVB0Ul28bPzYLMvEmVnt+tIZcpNwb8nEc196O8yvc5INLnuedeoGPOvXiO2oKuSzjx4nlqe/7OO5Lb7zx2lI45fuw2bgtaTXWiVlkIsuXKtC1SZicsEzS43m462N39GQC/ebPjhRCLRdKbEJmgYBciExTsQmSCgl2ITFCwC5EJCy046d6gJoUly0Ca6JCigR7pMeDy2iTIlisrvs+im56uohsULwxkuSIo5lgEMo61uK7YsGFDnhm2MeSFO1+4uEZtV9avU9vV9fXk9hcvXKRj1q5yWxX0ozva48VFjxxOlwM9deI4HfOmN97FbXf9CrXddpxLdnVQMLMhmYCdDn9dGnLpTKc8W1J3diEyQcEuRCYo2IXIBAW7EJmgYBciExa6Gj+ZTPDz536etA0HV+m4wVraVoKvPG5tBCvFXb6a3W3zVfCVleXk9mNHjtAxRYcvx0/HvO4egkSYst2nNi/Tq8/DMc+q2BryleK1a7yW3/nLG9Q22Eqf25jKBUDR5rUB2+BzNSIJSgDQXEsrL97wa6dV8LkqggZL1zevUdtoyOsUDgbpVfeyw7PDWp30tTga8eQq3dmFyAQFuxCZoGAXIhMU7EJkgoJdiExQsAuRCQuV3rY2t/DD1dWk7fraFTpuPE3LCb02l0GW20ERuoIn3RRBDa/+clryOhrUJSuCZJ3JhCenNEHbpd4yl/qWia3V58kiG1tcalob8ASU4TTohdRKz1WvHyT4RIlNnpYUASB4pdEuSZJJIK/VDbddG6xT22TEE1eurPPre+1yep9V0A5r6VBaphwGSU26swuRCQp2ITJBwS5EJijYhcgEBbsQmaBgFyITtpXezOwhAL8H4JK7//p82zEAXwVwN4BnAXzA3Xna2pzReIx/evqZpG39Mq8/ttRJyy5Hj3A5adgL6rQFdbqmQa2zVpGWjfrL/NRLMgYAKq7ywQvuf2+JZ6Itr6Sll/byCh0z5tOBtev8WJMxP4HG0rLRMKj/Nw2kq6UgG7EfXAdHeulLvNvir3O/x7PNIml2ELXYus6zMNfW09fPcMyl2d4gnXG42xp0fwXgvldtexDAo+7+ZgCPzv8WQtzCbBvs837rry4xej+Ah+ePHwbwvr11Swix19zsd/YT7v5y68wLmHV0FULcwux6gc7dHQD9XZ+ZnTGzVTNbHY+CyixCiH3lZoP9opmdBID5/5fYE939rLufdvfT3R7/fbMQYn+52WB/BMAD88cPAPjW3rgjhNgvdiK9fRnAuwDcbmYvAPgEgE8B+JqZfQTAcwA+sJODuTsq1v6pmy6gBwD9w+kMn0PHefZXLyjWN57wonwWfNVokbZLy0eCQolt/mmmiVoCOX8f9qAY5QTpVlTjLS41bQ4D2xaXcuqg0KORgo5NkCnXb/PX7Pjxo9R21+vvoLZjR9LZd+2g4GQZZMSVzudqPOJFJZdW+DWyPE7vswqKfY4m6TFNkCm3bbC7+4eI6Xe2GyuEuHXQL+iEyAQFuxCZoGAXIhMU7EJkgoJdiExYaMHJoizRWz6WdqTHs4l6vbSc5IFcNwHf32aQTTSpguyqTlrGaZFzAoCVFV6MMpLeqprbpoF8xTLYRkE21LAKCl+Cz0c7uHrKIi2j9br8/nJkJf06A8CvnLqT2u5+w+up7fZj6flvpjzDbjLgGWqDQdDPLUhjLDv83NqttK1quPS2uUmkzeCa0p1diExQsAuRCQp2ITJBwS5EJijYhcgEBbsQmbBQ6c1RoCEyw3TKs82uDdPS0GDCs5OqoHDk1hbPTqqnfJ8rh9JZXq0lnkVXF9yPIEEJjQU90QKbs8KMNc9Qa7X4OXdIph8A9Pvc1irTJ1eCS4D9TiB79rit5CaURdoPCzIHq4a/ZhsDXlTy8mVeePTy2mVqO/9S2nbhPC0TQfsE7rbgpBDilwAFuxCZoGAXIhMU7EJkgoJdiExY6Gq8FYY2SQio+YIwnNmCZdhWsEK70uLtgso2X2E+dCidVNE/cpSOKbq87ZIV/L22Q1peAUC3z23tVjpZp6n4Km015kkhrZK/MEvdYDWerIJXI57cMR7xBJTxkPu4Hqx0F01a5WkFt7lIrdkYcNva1XVqe+klbrty4dU9WObb1/h8OGlDVTc8GUd3diEyQcEuRCYo2IXIBAW7EJmgYBciExTsQmTCTto/PQTg9wBccvdfn2/7JIA/APDS/Gkfd/dvb3uwsoXjx44nbUHJNbRIPTMLpLd2IKF1ety2tMTr2h1aSbeb6gdSmBXcxyKwtdq8ZlkraG1F9xnUmauDtkX1hMs//eDqMUtLdgMLar9t8YSi0YCP2yAtxQCgU6SlqC5LGAJQ1TwRph2Mi+oNsnZNAACS2NRb5u3NKpLw8sw//4yO2cmd/a8A3JfY/ll3v2f+b9tAF0IcLNsGu7t/F0Ba9RdC/MKwm+/sHzWzJ8zsITO7bc88EkLsCzcb7J8H8CYA9wA4D+DT7IlmdsbMVs1sdbjFfyophNhfbirY3f2iu9c++4HuFwDcGzz3rLufdvfT/SX+O3EhxP5yU8FuZidv+PP9AJ7cG3eEEPvFTqS3LwN4F4DbzewFAJ8A8C4zuweAA3gWwB/u5GBF2cLKofTXewPX3qxkbnIZpNvh8lpviUtlvX46awzg0ttyINcVJX8/rYNzbgItsgoy2EbT9FelesRr/E3GvK7adHOd2lrgUhnIuY03+P6ub/AabiV49l03SHGsxmnJywKp15zvb2npELXdWXC59OgRvqxVIV0f0IJ78QbJzFv93v+hY7YNdnf/UGLzF7cbJ4S4tdAv6ITIBAW7EJmgYBciExTsQmSCgl2ITFhs+6emwYhIQB5UnKyIKVBP0OtxeW0y4ZLRlLSaAoCaZC6NxzxrLMpsa4IWVaOgjc9kGvg/IePqQCZr+Dl7xbPNeqTFEwC0ieRYBJUeI0m0E9yWllf4j7W65DoIuj+hDua+DGS+qFUWPDjvdjoMl5e5pNvbSF9zrRYPad3ZhcgEBbsQmaBgFyITFOxCZIKCXYhMULALkQkLld7qpsH1zbRkMBkGctI0rb2VBXefJKgBADqk3xwA1M7lpOE4LVFNA9mwrrmMM51y6a2uec+udicotEmkl1bQO65dBsUtPSjc2UpnawFAnxT8bJrgnIOimBb0MOv1uP+sd1/D9FwA48CP4RbPHtxYv0Zt1zZ44U6W3bZ0mPckrKr03LNClIDu7EJkg4JdiExQsAuRCQp2ITJBwS5EJiw2EcYdNVu5DjITioLU6CIJBADQDVafe0HNuKiVU7uTPl4TtB8KFp9hQSG0fo+vuEcJI/1u2ubOHfGKrzBPR3zVumV8Nb4iCSNRW65ul7+edcVX46soiYq0lBqPeYLPtXVe8vzaVd4v5Wpgu7bOV+PrJr2CHqkMRlpGRUleurMLkQkKdiEyQcEuRCYo2IXIBAW7EJmgYBciE3bS/ukuAH8N4ARmZd/OuvvnzOwYgK8CuBuzFlAfcHfevwez9k/9lXQbnE7QJsmNJHeUXMaJJLROl7d4spLLSSBJMlHrqiKo09YPpcMgOaXNZbnRKN3Kaf3KZTrm2vpLfH9B593lPvfxyJHD6e2H09sBoNeNarhxUzXm0uGIJK5cv75Ox6yvcdv1dW4bbnE5L6pTOJmkpdsmkBSnDWmvxWoQYmd39grAH7v7WwC8HcAfmdlbADwI4FF3fzOAR+d/CyFuUbYNdnc/7+4/nD/eAPAUgFMA7gfw8PxpDwN43z75KITYA17Td3YzuxvAWwE8BuCEu5+fmy5g9jFfCHGLsuNgN7MVAF8H8DF3f8Vv/9zdQb5VmdkZM1s1s9XR5saunBVC3Dw7CnYza2MW6F9y92/MN180s5Nz+0kAl1Jj3f2su59299O9Zd7bWgixv2wb7GZmmPVjf8rdP3OD6READ8wfPwDgW3vvnhBir9hJ1ttvAfgwgB+b2ePzbR8H8CkAXzOzjwB4DsAHttuRwdAq04fsBFJZt5/OUmsH0lvJ1SnUDZc0RtfT0hUATIl8Uk+55BJlmy0F5+yHeEujds1fto1r6eyqF194lo65cP48tU1HXHo7TOQ1ABiN70hur+tgPpa4JOpBzbhI8trcSPu/fpWrxNeDWnJbAz4fUf23SJ4dj9KZapvD6Fjp+aiDlmLbBru7/yMAJj7/znbjhRC3BvoFnRCZoGAXIhMU7EJkgoJdiExQsAuRCQtu/1Rh/Xpa8ugMO3TcykpaZlha5u1xiiB7bTjgv+S7tsazw7Y20r5XEy6RkLqLAIAjR7l0dUd9ezCO97YyS89VNB9BwiGmBT+BJmhRtUWyza4WXNa6PuCy53iTy2uDoLUSa9c03OLH2trgGWrjIR9XBfJgKL2RtmKbG/w6ZfJxVHxTd3YhMkHBLkQmKNiFyAQFuxCZoGAXIhMU7EJkwmKlt6rGYD0tX7VIHzUAsCL9nlS0uJzRImMAYHOTSzUbG7xf1+bGenK717y/1nKPZ+ZVYz5uPOJSUzPmhR4LIvH0OtyPlcO8912nw+exTfqNAUBFeo5dvcr74kUZcevrXIba3OByXlWTIqHOpUgmhQHAeMhfs3oS9NNzLlOOScFMJhvO9pc+r4YUogR0ZxciGxTsQmSCgl2ITFCwC5EJCnYhMmGhq/GAA6QmWy8oGrdEFpL77aBlVMNXP0vwZIEoKaRNslqKFq8lV7b4qu+IrFgDwOWXeEJOlPjRkFXaqHbaaBit+vIV5oYk3QBAM0nbpkF7oiGpxQYAgwFXJ6bBPBZF+hIvW1ydqINkknGQ7DINatAhSBqqKjLO+LXjBbEFY3RnFyITFOxCZIKCXYhMULALkQkKdiEyQcEuRCZsK72Z2V0A/hqzlswO4Ky7f87MPgngDwC8NH/qx9392+HOvIFX6RpeHiQRjLfSiQ7uPGEhasUzGHDpajTgSRXTaVqiKpkMAqChzXSAajNIuCDJETN4sgOrdRa1BYpkysICW3De9TR9vGkkXQWy3CiQ5aLkj7JM26qKn9cwSFAajYJEnikfZyQhBwDM0rayxe/F7GXhr8jOdPYKwB+7+w/N7BCAH5jZd+a2z7r7X+xgH0KIA2Ynvd7OAzg/f7xhZk8BOLXfjgkh9pbX9J3dzO4G8FYAj803fdTMnjCzh8zstr12Tgixd+w42M1sBcDXAXzM3a8D+DyANwG4B7M7/6fJuDNmtmpmq5OgIIMQYn/ZUbCbWRuzQP+Su38DANz9orvXPivB8QUA96bGuvtZdz/t7qc7Pd7UQQixv2wb7GZmAL4I4Cl3/8wN20/e8LT3A3hy790TQuwVO1mN/y0AHwbwYzN7fL7t4wA+ZGb3YKYDPQvgD7fbUV1Nce3KxaRtK6gZh0sX0vvj6gmqmss4dSDLTaLMJaJ3dLu8dVUZnNeUyFMAMA7kHyuijL40TSCTFUF9tJLIQrNx3FaTF6cJZL4qkAenEy55BcoblWAD1zEa8WtgPOKtoRDMYyuaR5KpFgy5qV/I7GQ1/h+Rlu9iTV0IcUuhX9AJkQkKdiEyQcEuRCYo2IXIBAW7EJmw0IKTVV1h7Uq6kGJDMsoAYEIy4saBdBWpFq0ykKGCwpdlOz1dnc7NSW91ExRsDLShdtCSCUXaf2uCDLVAu3LnPrICnABQksqdFmUBRsUtA8kusjH3o0y5asplvqIIWo4Zf106QXFUph1G10A1CXRngu7sQmSCgl2ITFCwC5EJCnYhMkHBLkQmKNiFyISFSm9NXWHz2lrSFhXrm7K+YUGWVNHmspB3+GlbIJW1pul9TsfBe2bQeys6VhnIWoVz/50VKQykpibobVYEImZraZnaev20HBll+g03g0zFoBhlHUhvrJhjNY3kumA+goqOvS5/zdqk5xzAe8QNg+y70VY6+64J5Fzd2YXIBAW7EJmgYBciExTsQmSCgl2ITFCwC5EJC5XevHFUk3R2W9SbzYlsVASFFzstfmrtIOstgmaAOd9f1Acu6pUWvQs3DZevaqJgRpLMJOhfFk1Vp92mti7JBGyCHmtRkc3RiGdFFsFsFeQEPJBtm0AebAX919Dwa65q+Bxvbqb7KQwG6b6IADAhve+iDEDd2YXIBAW7EJmgYBciExTsQmSCgl2ITNh2Nd7MegC+C6A7f/7fufsnzOyNAL4C4DiAHwD4sLvzJUcABkdJWuTUQa2zgiSMtEpe+60bJLuUwRJzUwfV60h9ulYnSFoJatrVwbHCFfeKz9WUJHFMopZGwSp41OIp0jRYMknk+5isMAPAdMJtrZK/1oXRhlh0DC1cB8DCWnjcj3rM1YThYCO5PVqNp5dHkPC0kzv7GMC73f03MWvPfJ+ZvR3AnwP4rLv/GwBXAXxkB/sSQhwQ2wa7zxjM/2zP/zmAdwP4u/n2hwG8bz8cFELsDTvtz17OO7heAvAdAP8CYN39/9f+fQHAqX3xUAixJ+wo2N29dvd7ALwBwL0A/u1OD2BmZ8xs1cxW66AogBBif3lNq/Huvg7gHwD8OwBHzezlFYk3ADhHxpx199PufroMFquEEPvLtsFuZneY2dH54z6A9wB4CrOg//350x4A8K198lEIsQfsJBHmJICHzazE7M3ha+7+P8zspwC+Ymb/GcD/BfDF7XZkZihJG5xuUI/NiZtt0mIIiOu7RXXhQGqWzfxIE7USiiS0quYyThV85amCJI5JlZbYqjGX3iakxh8AFOC2UBqq03NcBJJX5Eck9EUtpTwUCMn+guujCe6PUTLXNJAcWZunMOemmzZWXOHbPtjd/QkAb01sfwaz7+9CiF8A9As6ITJBwS5EJijYhcgEBbsQmaBgFyITzIOspj0/mNlLAJ6b/3k7gMsLOzhHfrwS+fFKftH8+FV3vyNlWGiwv+LAZqvufvpADi4/5EeGfuhjvBCZoGAXIhMOMtjPHuCxb0R+vBL58Up+afw4sO/sQojFoo/xQmTCgQS7md1nZv9sZk+b2YMH4cPcj2fN7Mdm9riZrS7wuA+Z2SUze/KGbcfM7Dtm9rP5/7cdkB+fNLNz8zl53MzeuwA/7jKzfzCzn5rZT8zsP863L3ROAj8WOidm1jOz75nZj+Z+/Nl8+xvN7LF53HzVzHjF1RTuvtB/AErMylr9GoAOgB8BeMui/Zj78iyA2w/guO8E8DYAT96w7b8AeHD++EEAf35AfnwSwH9a8HycBPC2+eNDAP4fgLcsek4CPxY6J5jl867MH7cBPAbg7QC+BuCD8+3/DcB/eC37PYg7+70Annb3Z3xWevorAO4/AD8ODHf/LoC1V22+H7PCncCCCngSPxaOu5939x/OH29gVhzlFBY8J4EfC8Vn7HmR14MI9lMAnr/h74MsVukA/t7MfmBmZw7Ih5c54e7n548vADhxgL581MyemH/M3/evEzdiZndjVj/hMRzgnLzKD2DBc7IfRV5zX6B7h7u/DcC/B/BHZvbOg3YImL2zgxfG2W8+D+BNmPUIOA/g04s6sJmtAPg6gI+5+/UbbYuck4QfC58T30WRV8ZBBPs5AHfd8DctVrnfuPu5+f+XAHwTB1t556KZnQSA+f+XDsIJd784v9AaAF/AgubEzNqYBdiX3P0b880Ln5OUHwc1J/Njr+M1FnllHESwfx/Am+crix0AHwTwyKKdMLNlMzv08mMAvwvgyXjUvvIIZoU7gQMs4PlycM15PxYwJzYr+vZFAE+5+2duMC10Tpgfi56TfSvyuqgVxletNr4Xs5XOfwHwJwfkw69hpgT8CMBPFukHgC9j9nFwitl3r49g1jPvUQA/A/C/ARw7ID/+BsCPATyBWbCdXIAf78DsI/oTAB6f/3vvouck8GOhcwLgNzAr4voEZm8sf3rDNfs9AE8D+O8Auq9lv/oFnRCZkPsCnRDZoGAXIhMU7EJkgoJdiExQsAuRCQp2ITJBwS5EJijYhciEfwWS6MYoPlDDmwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    prediction = model(sample_image.unsqueeze(0).to(device))\n",
    "    plt.imshow(prediction.cpu().reshape(3,32,32).permute(1,2,0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3677.072789,
   "end_time": "2022-08-16T16:51:36.531962",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-16T15:50:19.459173",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "39276ad91ea849078a20583ea7790c1c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3db65bff75384c06b18eff30307079ea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5b8b9c59cc6843deaacc861f29598754",
       "placeholder": "​",
       "style": "IPY_MODEL_ee70338f83fd4e34853d345f09c88a51",
       "value": ""
      }
     },
     "47ec0885a82543b29e6ce8d739886f87": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_39276ad91ea849078a20583ea7790c1c",
       "max": 170498071.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4eb37aa2d6dc430ba5adc08f09688e2b",
       "value": 170498071.0
      }
     },
     "4be8c4d2cd2e4d2a96b4cd381eae9935": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_54a6485aae824f9eb72c3f207d0ee6d1",
       "placeholder": "​",
       "style": "IPY_MODEL_e05ef1266cb649d2aa674ea3388b4f83",
       "value": " 170499072/? [00:05&lt;00:00, 33053742.01it/s]"
      }
     },
     "4eb37aa2d6dc430ba5adc08f09688e2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "54a6485aae824f9eb72c3f207d0ee6d1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5b8b9c59cc6843deaacc861f29598754": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ad9219f12b0645bb8919646373f57f2d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3db65bff75384c06b18eff30307079ea",
        "IPY_MODEL_47ec0885a82543b29e6ce8d739886f87",
        "IPY_MODEL_4be8c4d2cd2e4d2a96b4cd381eae9935"
       ],
       "layout": "IPY_MODEL_b20e77c600164eaab73d63b8b9c58647"
      }
     },
     "b20e77c600164eaab73d63b8b9c58647": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e05ef1266cb649d2aa674ea3388b4f83": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ee70338f83fd4e34853d345f09c88a51": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
